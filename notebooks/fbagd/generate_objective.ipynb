{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8022bfb4-c69b-4cb7-a24c-fec017cc3661",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T16:34:31.165042Z",
     "start_time": "2024-05-03T16:34:30.817464Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import dill\n",
    "import requests\n",
    "import xmltodict\n",
    "import cvxpy as cp\n",
    "import itertools\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "sns.set(style='darkgrid', palette='viridis', context='talk')\n",
    "\n",
    "os.chdir(os.path.expanduser('~/vivarium-ecoli'))\n",
    "\n",
    "from ecoli.processes.metabolism_redux import NetworkFlowModel, FlowResult"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a143cbbb-3570-4548-bc24-f499c070a880",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import simulation output\n",
    "\n",
    "Before running this, run a sim in ecoli/experiments/metabolism_redux_sim.py with -n 2 to generate a simulation output. This is necessary to replicate the simulation environment. Use the default .json config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09934d23-df11-4304-9ef4-eb81f0b818c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T16:06:23.701029Z",
     "start_time": "2024-05-03T16:06:23.696962Z"
    }
   },
   "source": [
    "time = '10'\n",
    "date = '2024-04-27'\n",
    "experiment = 'convex_kinetics'\n",
    "entry = f'{experiment}_{time}_{date}'\n",
    "folder = f'out/cofactors/{entry}/'"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b31e4a2e-0491-4e96-946d-9bca6cd43d79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T16:06:23.813295Z",
     "start_time": "2024-05-03T16:06:23.699616Z"
    }
   },
   "source": [
    "output = np.load(folder + '0_output.npy',allow_pickle='TRUE').item()\n",
    "# output = np.load(r\"out/geneRxnVerifData/output_glc.npy\", allow_pickle=True, encoding='ASCII').tolist()\n",
    "output = output['agents']['0']\n",
    "fba = output['listeners']['fba_results']\n",
    "mass = output['listeners']['mass']\n",
    "bulk = pd.DataFrame(output['bulk'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc9f4494-cab0-43d1-bae7-85572d8e4166",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T16:06:24.592918Z",
     "start_time": "2024-05-03T16:06:23.813581Z"
    }
   },
   "source": [
    "f = open(folder + 'agent_steps.pkl', 'rb')\n",
    "agent = dill.load(f)\n",
    "f.close()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27c1e87b-1ff5-4d04-89ac-5aa2bf6dbb9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T16:06:26.080734Z",
     "start_time": "2024-05-03T16:06:25.725364Z"
    }
   },
   "source": [
    "stoichiometry = agent['ecoli-metabolism-redux-classic'].stoichiometry\n",
    "process_rxn_names = agent['ecoli-metabolism-redux-classic'].reaction_names\n",
    "# maintenance_reaction = agent['ecoli-metabolism-redux-classic'].model.maintenance_reaction\n",
    "# stoichiometry[\"maintenance_reaction\"] = maintenance_reaction\n",
    "\n",
    "bad_rxns = [\"RXN-12440\", \"TRANS-RXN-121\", \"TRANS-RXN-300\", \"TRANS-RXN-8\", \"R15-RXN-MET/CPD-479//CPD-479/MET.25.\",\"DISULFOXRED-RXN[CCO-PERI-BAC]-MONOMER0-4152/MONOMER0-4438//MONOMER0-4438/MONOMER0-4152.71.\"]\n",
    "# generate carbon mistake in parca, efflux/influx proton gen, iron cheating, mass gen\n",
    "# for rxn in bad_rxns:\n",
    "#    stoichiometry.pop(rxn, None)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "cc853a7f-8d04-42f7-97d1-7ec846a4ef41",
   "metadata": {},
   "source": [
    "Pandas automatically understands dicts of dicts as matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b1bb0c-c85e-442c-8482-5d24d54fba82",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Test changing nutrient composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "velocities = fba[\"estimated_fluxes\"][4]\n",
    "# use reaction names to make a dict\n",
    "d_velocities = {k: v for k, v in zip(process_rxn_names, velocities)}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T16:06:27.247579Z",
     "start_time": "2024-05-03T16:06:27.229585Z"
    }
   },
   "id": "f05b6d54fe11d842",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Filter S matrix to only include nonzero fluxes."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d4033fc02bf2dda9"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# only include nonzero fluxes in solution.velocities\n",
    "nonzero_velocities = {k: v for k, v in d_velocities.items() if v != 0}\n",
    "nonzero_velocities\n",
    "\n",
    "# reaction indices with nonzero fluxes\n",
    "nonzero_S_indices = [process_rxn_names.index(k) for k in nonzero_velocities.keys()]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T16:06:28.492353Z",
     "start_time": "2024-05-03T16:06:28.455079Z"
    }
   },
   "id": "4444a0cef2241182",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T16:06:28.934245Z",
     "start_time": "2024-05-03T16:06:28.893101Z"
    }
   },
   "id": "d5eebf9bd76509b",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Use nonzero_velocities to filter S matrix\n",
    "S_matrix = stoichiometry[:, nonzero_S_indices]\n",
    "\n",
    "# remove rows of S_used that sum to zero.\n",
    "S_matrix = S_matrix[(S_matrix != 0).any(axis=1)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T16:06:30.711784Z",
     "start_time": "2024-05-03T16:06:30.361616Z"
    }
   },
   "id": "5a473c3838843532",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "S_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-03T16:06:30.775025Z",
     "start_time": "2024-05-03T16:06:30.697304Z"
    }
   },
   "id": "d6352a7628b85d51",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get protein counts from scratch"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b4d72e68d02159d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# First test. Single flux set. No eQuilibrator or regulation."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8db107005029e18"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "# sort nonzero_velocities to be in same order as S_matrix columns.\n",
    "vE_dict = nonzero_velocities\n",
    "vE = np.array([np.array(list(vE_dict.values()))])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T22:38:30.402763Z",
     "start_time": "2024-04-27T22:38:30.136660Z"
    }
   },
   "id": "c76654daa337ecba",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "Sd = pd.DataFrame(S_matrix, columns=[k for k in nonzero_velocities.keys()])\n",
    "# Sd = pd.DataFrame(stoich_dict, dtype=np.int8).fillna(0).astype(np.int8)\n",
    "# Sd = Sd.iloc[0:7, 0:2]\n",
    "\n",
    "\n",
    "\n",
    "Sd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T22:40:11.950950Z",
     "start_time": "2024-04-27T22:40:11.712354Z"
    }
   },
   "id": "a1d4e1bd56a10a69",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "# K_eq = np.log(keq)\n",
    "# K_eq_mod = K_eq[:, np.newaxis].T\n",
    "# vE = np.array([[90, 70, -30, 50], [100, 100, 30, 50], [110, 60, 75, 50]])\n",
    "\n",
    "# n_flux_set = vE.shape[0]\n",
    "n_flux_set = 1\n",
    "Sr = None\n",
    "\n",
    "# K_eq[vE < 0] = 1/K_eq[vE < 0]\n",
    "\n",
    "lvE = np.log(np.abs(vE))\n",
    "pd.DataFrame(np.concatenate([vE, np.sign(vE)]), columns=list(nonzero_velocities.keys()),\n",
    "             index=[\"$v_1$\", \"sign 1\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T22:40:13.842204Z",
     "start_time": "2024-04-27T22:40:13.794419Z"
    }
   },
   "id": "bc86f963c6a6b11b",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "# set up variables\n",
    "\n",
    "n_met = len(Sd.index)\n",
    "n_rxn = len(Sd.columns)\n",
    "\n",
    "S_mol = np.array(Sd)\n",
    "S = np.sign(S_mol) #\n",
    "S_s = -np.copy(S) # reverse neg sign\n",
    "S_p = np.copy(S)\n",
    "S_s[S > 0] = 0 # zeros products\n",
    "S_p[S < 0] = 0 # zeros substrates\n",
    "S_i = np.copy(np.array(Sr) == -1) # reaction direction does not matter\n",
    "S_a = np.copy(np.array(Sr) == 1)\n",
    "\n",
    "\n",
    "S_s_nz = np.array(S_s.nonzero())\n",
    "S_p_nz = np.array(S_p.nonzero())\n",
    "S_i_nz = np.array(S_i.nonzero())\n",
    "S_a_nz = np.array(S_a.nonzero())\n",
    "S_s_mol = np.abs(S_mol)[S_s.nonzero()]\n",
    "S_p_mol = np.abs(S_mol)[S_p.nonzero()]\n",
    "\n",
    "# TODO Refactor all the below lines as one liners\n",
    "# first coordinate, e.g. metabolites w nonzero substrate/product coeff across all reactions. also works as substrate indices.\n",
    "met_s_nz = S_s_nz[0, :]\n",
    "met_p_nz = S_p_nz[0, :]\n",
    "met_i_nz = S_i_nz[0, :] if Sr is not None else None\n",
    "met_a_nz = S_a_nz[0, :] if Sr is not None else None\n",
    "\n",
    "# second coordinate, e.g. reactions indices for those concentrations. works to index substrates as well.\n",
    "rxn_s_nz = S_s_nz[1, :]\n",
    "rxn_p_nz = S_p_nz[1, :]\n",
    "rxn_i_nz = S_i_nz[1, :] if Sr is not None else None\n",
    "rxn_a_nz = S_a_nz[1, :] if Sr is not None else None\n",
    "\n",
    "# one dim is always 2\n",
    "n_Km_s = np.max(met_s_nz.shape)\n",
    "n_Km_p = np.max(met_p_nz.shape)\n",
    "n_Km_i = np.max(met_i_nz.shape) if Sr is not None else None\n",
    "n_Km_a = np.max(met_a_nz.shape) if Sr is not None else None\n",
    "\n",
    "c = cp.Variable([n_met, n_flux_set])\n",
    "Km_s = cp.Variable(n_Km_s)\n",
    "Km_p = cp.Variable(n_Km_p)\n",
    "Km_i = cp.Variable(n_Km_i) if n_Km_i else None\n",
    "Km_a = cp.Variable(n_Km_a) if n_Km_a else None\n",
    "\n",
    "cfwd = cp.Variable(n_rxn)\n",
    "crev = cp.Variable(n_rxn)\n",
    "\n",
    "# define y vecs\n",
    "y_s_t = []\n",
    "y_p_t = []\n",
    "y_i_t = []\n",
    "y_a_t = []\n",
    "\n",
    "# define Km positions by nonzero S matrix concentrations. Activation is reverse val of inhibition.\n",
    "# TODO Add molecularity here.\n",
    "for i in range(n_flux_set):\n",
    "    y_s_t.append(cp.multiply(S_s_mol, c[met_s_nz, i] - Km_s))\n",
    "    y_p_t.append(cp.multiply(S_p_mol, c[met_p_nz, i] - Km_p))\n",
    "    y_i_t.append(c[met_i_nz, i] - Km_i if n_Km_i else None)\n",
    "    y_a_t.append(-(c[met_a_nz, i] - Km_a) if n_Km_a else None)\n",
    "\n",
    "y_s = cp.vstack(y_s_t)\n",
    "y_p = cp.vstack(y_p_t)\n",
    "y_i = cp.vstack(y_i_t)\n",
    "y_a = cp.vstack(y_a_t)\n",
    "\n",
    "# saturation stacks\n",
    "y_f_vec = [y_s]\n",
    "y_r_vec = [y_p]\n",
    "if n_Km_i:\n",
    "    y_f_vec.append(y_i)\n",
    "    y_r_vec.append(y_i)\n",
    "if n_Km_a:\n",
    "    y_f_vec.append(y_a)\n",
    "    y_r_vec.append(y_a)\n",
    "\n",
    "y_f = cp.hstack(y_f_vec)\n",
    "y_r = cp.hstack(y_r_vec)\n",
    "\n",
    "print(f\"Number of metabolites: {n_met}, number of reactions: {n_rxn}, number of flux sets: {n_flux_set}\",\n",
    "      f\"Number of Km_s: {n_Km_s}, number of Km_p: {n_Km_p}, number of Km_i: {n_Km_i}, number of Km_a: {n_Km_a}\",\n",
    "      f\"Number of concentrations: {c.shape}, number of y_f: {y_f.shape}, number of y_r: {y_r.shape}\", sep='\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T22:40:16.103974Z",
     "start_time": "2024-04-27T22:40:16.071518Z"
    }
   },
   "id": "de475b12e074e56d",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "# number of saturation terms for sub, prod\n",
    "S_s_comb = np.concatenate((S_s, S_i, S_a), axis=0) if Sr else S_s\n",
    "S_p_comb = np.concatenate((S_p, S_i, S_a), axis=0) if Sr else S_p\n",
    "n_alpha = np.sum(np.power(2, np.sign(S_s_comb).sum(axis=0)) - 1)\n",
    "n_beta = np.sum(np.power(2, np.sign(S_p_comb).sum(axis=0)) - 1)\n",
    "\n",
    "# saturation matrix setup, first sub, then inhib, then act.\n",
    "C_alpha = np.zeros([n_alpha, len(met_s_nz) + len(met_i_nz) + len(met_a_nz)]) if Sr else np.zeros([n_alpha, len(met_s_nz)])\n",
    "C_beta = np.zeros([n_beta, len(met_p_nz) + len(met_i_nz) + len(met_a_nz)]) if Sr else np.zeros([n_beta, len(met_p_nz)])\n",
    "\n",
    "# to separate different reactions saturation terms to their individual reaction equations.\n",
    "d_alpha = np.zeros(n_alpha, dtype=np.int64)\n",
    "d_beta = np.zeros(n_beta, dtype=np.int64)\n",
    "\n",
    "\n",
    "idx = 0\n",
    "\n",
    "for i in range(n_rxn):\n",
    "\n",
    "    # pick one reaction at a time (get substrate indicies)\n",
    "    #idx_cur_rxn = rxn_s_nz == i\n",
    "    # TODO This does not properly multiply by molecularity. Alternatively, generate C_alpha and\n",
    "    # TODO beta without molecularity (first ==1) and then multiply by molecularity in the end.\n",
    "    idx_cur_rxn = np.concatenate((rxn_s_nz == i, rxn_i_nz == i, rxn_a_nz == i)) if Sr else rxn_s_nz == i\n",
    "\n",
    "    # generates all binary permutations minus the first one since that would result in -1\n",
    "    sat_perm = np.array(list(itertools.product([0, 1], repeat=sum(idx_cur_rxn))))\n",
    "    sat_perm = sat_perm[1:, :]\n",
    "\n",
    "    r, _ = sat_perm.shape\n",
    "\n",
    "    # replace zeros with saturation matrix\n",
    "    C_alpha[idx:(idx+r), idx_cur_rxn] = sat_perm\n",
    "    d_alpha[idx:(idx+r)] = i\n",
    "\n",
    "    idx += r # add row #\n",
    "\n",
    "idx = 0\n",
    "\n",
    "for i in range(n_rxn):\n",
    "    idx_cur_rxn = np.concatenate((rxn_p_nz == i, rxn_i_nz == i, rxn_a_nz == i)) if Sr else rxn_p_nz == i\n",
    "\n",
    "    sat_perm = np.array(list(itertools.product([0, 1], repeat=sum(idx_cur_rxn))))\n",
    "    sat_perm = sat_perm[1:, :]\n",
    "\n",
    "    r, _ = sat_perm.shape\n",
    "\n",
    "    C_beta[idx:(idx+r), idx_cur_rxn] = sat_perm\n",
    "    d_beta[idx:(idx+r)] = i\n",
    "\n",
    "    idx += r # add row #"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T22:40:23.419331Z",
     "start_time": "2024-04-27T22:40:23.311164Z"
    }
   },
   "id": "c89e08613f9cc08a",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "n_lse_terms = np.max(np.power(2, S_s.sum(axis=0)) +  np.power(2, S_p.sum(axis=0)) - 2)\n",
    "LSE_expr = []\n",
    "denom_expr = []\n",
    "\n",
    "sign = np.sign(vE)\n",
    "lvE = np.log(sign * vE)\n",
    "\n",
    "for j in range(n_flux_set):\n",
    "    for i in range(n_rxn):\n",
    "        # sum terms are separate in logsumexp. one per saturation term (row in C_alpha, C_beta)\n",
    "\n",
    "        n_term_s = np.sum(d_alpha == i)\n",
    "        n_term_p = np.sum(d_beta == i)\n",
    "        n_term = n_term_s + n_term_p\n",
    "\n",
    "        Km_s_idx = np.nonzero(S_s_nz[1, :] == i)\n",
    "        S_s_idx = S_s_nz[0, S_s_nz[1, :] == i] # negate -1 entries\n",
    "\n",
    "        Km_p_idx = np.nonzero(S_p_nz[1, :] == i)\n",
    "        S_p_idx = S_p_nz[0, S_p_nz[1, :] == i]\n",
    "\n",
    "        if sign[j, i] == 1:\n",
    "            LSE_expr.append(cp.hstack( [\n",
    "                                         lvE[j, i] + (C_alpha @ cp.vec(y_f[j, :]))[d_alpha == i]\n",
    "                                            - cp.multiply(np.ones(n_term_s), - S.T[i, S_s_idx] @ cp.vec(y_s[j, Km_s_idx])) - cfwd[i],\n",
    "                                         lvE[j, i] + (C_beta @ cp.vec(y_r[j, :]))[d_beta == i]\n",
    "                                            - cp.multiply(np.ones(n_term_p), - S.T[i, S_s_idx] @ cp.vec(y_s[j, Km_s_idx])) - cfwd[i],\n",
    "\n",
    "                                         lvE[j, i] + 0 - cp.multiply(np.ones(1), -S.T[i, S_s_idx] @ cp.vec(y_s[j, Km_s_idx]))  - cfwd[i],\n",
    "\n",
    "                                         cp.multiply(np.ones(1), S.T[i, S_p_idx] @ cp.vec(y_p[j, Km_p_idx]))  + crev[i]\n",
    "                                            - cp.multiply(np.ones(1), -S.T[i, S_s_idx] @ cp.vec(y_s[j, Km_s_idx]))  - cfwd[i],\n",
    "\n",
    "                                       ]\n",
    "                                     )\n",
    "                           )  # remove +1 here, could also have cfwd outside objec.\n",
    "\n",
    "            denom_expr.append(cp.multiply(np.ones(1), -S.T[i, S_s_idx] @ cp.vec(y_s[j, Km_s_idx])) + cfwd[i],)\n",
    "\n",
    "\n",
    "        # keep saturation term the same, switch around fwd and rev terms. flip all signs with S matrix since it's signed.\n",
    "        if sign[j, i] == -1:\n",
    "            LSE_expr.append(cp.hstack( [ lvE[j, i] + (C_alpha @ cp.vec(y_f[j, :]))[d_alpha == i]\n",
    "                                            - cp.multiply(np.ones(n_term_s), S.T[i, S_p_idx] @ cp.vec(y_p[j, Km_p_idx])) - crev[i],\n",
    "\n",
    "                                         lvE[j, i] + (C_beta @ cp.vec(y_r[j, :]))[d_beta == i]\n",
    "                                            - cp.multiply(np.ones(n_term_p), S.T[i, S_p_idx] @ cp.vec(y_p[j, Km_p_idx])) - crev[i],\n",
    "\n",
    "                                         lvE[j, i] + 0 - cp.multiply(np.ones(1), S.T[i, S_p_idx] @ cp.vec(y_p[j, Km_p_idx])) - crev[i],\n",
    "\n",
    "                                         cp.multiply(np.ones(1), - S.T[i, S_s_idx] @ cp.vec(y_s[j, Km_s_idx]))  + cfwd[i]\n",
    "                                            - cp.multiply(np.ones(1), S.T[i, S_p_idx] @ cp.vec(y_p[j, Km_p_idx])) - crev[i],\n",
    "\n",
    "                                       ]\n",
    "                                     )\n",
    "                           )\n",
    "\n",
    "            denom_expr.append(cp.multiply(np.ones(1), S.T[i, S_p_idx] @ cp.vec(y_p[j, Km_p_idx])) + crev[i])\n",
    "\n",
    "\n",
    "#LSE_expr = cp.vstack(LSE_expr)\n",
    "LSE_expr[0:10]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T22:40:25.984316Z",
     "start_time": "2024-04-27T22:40:25.681642Z"
    }
   },
   "id": "3d8f5357685b7737",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "l = 0.001\n",
    "e = 0.001\n",
    "f = 0.000001\n",
    "reg =  cp.sum(cp.hstack([cfwd, crev, cp.vec(c)])) + cp.sum(cp.hstack([-Km_s, -Km_p])) # regularization\n",
    "reg2 = cp.norm1(cp.hstack([cfwd, crev, cp.vec(c)])) + cp.norm1(cp.hstack([-Km_s, -Km_p])) # regularization\n",
    "reg3 = cp.sum(cp.huber(cp.hstack([y_s, y_p]), 1)) # issue with matrix\n",
    "\n",
    "if n_Km_i:\n",
    "    reg += cp.sum(cp.hstack([-Km_i]))\n",
    "if n_Km_a:\n",
    "    reg += cp.sum(cp.hstack([-Km_a]))\n",
    "#reg3 = cp.norm1(cp.hstack([y_s, y_p])) # take a look at this\n",
    "\n",
    "loss = 0\n",
    "for i in range(len(LSE_expr)):\n",
    "    loss += cp.norm1(cp.pos(cp.log_sum_exp(LSE_expr[i])))\n",
    "for i in range(len(denom_expr)):\n",
    "    loss += 0.01 * denom_expr[i]\n",
    "loss += l * reg\n",
    "loss += e * reg2\n",
    "loss += f * reg3\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T22:40:31.678699Z",
     "start_time": "2024-04-27T22:40:31.515686Z"
    }
   },
   "id": "9358b3a6deca504b",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "constr = [cp.hstack([cfwd, crev, cp.vec(c), Km_s, Km_p]) >= -12,\n",
    "          cp.hstack([cfwd, crev, cp.vec(c), Km_s, Km_p]) <= 18,\n",
    "          ]\n",
    "\n",
    "if n_Km_i:\n",
    "    constr.extend([Km_i >= -12, Km_i <= 18])\n",
    "if n_Km_a:\n",
    "    constr.extend([Km_a >= -12, Km_a <= 18])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T22:40:40.335257Z",
     "start_time": "2024-04-27T22:40:39.601684Z"
    }
   },
   "id": "9b4121385493ef7",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "# haldane = []\n",
    "# fwd_flux = []\n",
    "# \n",
    "# for i, r in enumerate(S.T):\n",
    "#     Km_s_idx = np.nonzero(S_s_nz[1, :] == i)\n",
    "#     S_s_idx = S_s_nz[0, S_s_nz[1, :] == i] # negate -1 entries\n",
    "# \n",
    "#     Km_p_idx = np.nonzero(S_p_nz[1, :] == i)\n",
    "#     S_p_idx = S_p_nz[0, S_p_nz[1, :] == i]\n",
    "# \n",
    "#     haldane.append(K_eq[i] == cfwd[i] - crev[i] + r[S_p_idx] @ Km_p[Km_p_idx] - (-r[S_s_idx]) @ Km_s[Km_s_idx])\n",
    "# \n",
    "# for j in range(n_flux_set):\n",
    "#     for i, r in enumerate(S.T):\n",
    "#         Km_s_idx = np.nonzero(S_s_nz[1, :] == i)\n",
    "#         S_s_idx = S_s_nz[0, S_s_nz[1, :] == i] # negate -1 entries\n",
    "# \n",
    "#         Km_p_idx = np.nonzero(S_p_nz[1, :] == i)\n",
    "#         S_p_idx = S_p_nz[0, S_p_nz[1, :] == i]\n",
    "# \n",
    "#         if sign[j, i] == 1:\n",
    "#             fwd_flux.append(cfwd[i] + (-r[S_s_idx]) @ cp.vec(y_s[j, Km_s_idx]) - (crev[i] + r[S_p_idx] @ cp.vec(y_p[j, Km_p_idx]))  >= 0)  # add minus since s matrix has minus\n",
    "#             # equilibrium.append(r @ c <= K_eq[i])\n",
    "# \n",
    "#         if sign[j, i] == -1:\n",
    "#             fwd_flux.append(cfwd[i] + (-r[S_s_idx]) @ cp.vec(y_s[j, Km_s_idx]) - (crev[i] + r[S_p_idx] @ cp.vec(y_p[j, Km_p_idx]))  <= 0)  # add minus since s matrix has minus\n",
    "#             # equilibrium.append(r @ c >= K_eq[i])\n",
    "# \n",
    "# \n",
    "#     constr.extend([cp.multiply(S.T @ cp.vec(c[:, j]), sign[j, :])  <= cp.multiply(K_eq, sign[j, :])])\n",
    "# \n",
    "# constr.extend(haldane)\n",
    "# constr.extend(fwd_flux)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T22:41:13.325636Z",
     "start_time": "2024-04-27T22:41:12.367338Z"
    }
   },
   "id": "6b9c72f7a4f4bc9",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "p = cp.Problem(cp.Minimize(loss), constr)\n",
    "p.solve(verbose=False, solver=cp.ECOS)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T22:41:37.070736Z",
     "start_time": "2024-04-27T22:41:13.349692Z"
    }
   },
   "id": "af43680b9ab31e2f",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# print('Substrate Km:', [f'{val:.3f}' for val in np.exp(Km_s.value)])\n",
    "# print('Product Km:', [f'{val:.3f}' for val in np.exp(Km_p.value)])\n",
    "# print('Fwd kcat:', [f'{val:.3f}' for val in np.exp(cfwd.value)])\n",
    "# print('Rev kcat:', [f'{val:.3f}' for val in np.exp(crev.value)])\n",
    "#\n",
    "# concs = np.exp(c.value).T\n",
    "# for row in concs:\n",
    "#     print('Concentration:', [f'{val:.4f}' for val in row])\n",
    "#\n",
    "# if n_Km_i:\n",
    "#     print('Inhibition Km:', [f'{val:.3f}' for val in np.exp(Km_i.value)])\n",
    "# if n_Km_a:\n",
    "#     print('Activation Km:', [f'{val:.3f}' for val in np.exp(Km_a.value)])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7f796ee2910415f",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "for v in LSE_expr:\n",
    "    #print(v.value)\n",
    "    print(logsumexp(v.value))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T22:41:52.854462Z",
     "start_time": "2024-04-27T22:41:51.989144Z"
    }
   },
   "id": "ddf2dc25e7f4334d",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Perfect? Wow."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ce549cb4f37d276"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Check flux reconstruction with inhibition/activation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "188ff48dabedc00"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "reconstructed_vE = np.zeros(vE.shape)\n",
    "\n",
    "for j in range(n_flux_set):\n",
    "    sat_expr = []\n",
    "    fwd_sat = np.zeros(n_rxn)\n",
    "    back_sat = np.zeros(n_rxn)\n",
    "    sat = np.zeros(n_rxn)\n",
    "\n",
    "    for i in range(n_rxn):\n",
    "        # sum terms are separate in logsumexp. one per saturation term (row in C_alpha, C_beta)\n",
    "        n_term_s = np.sum(d_alpha == i)\n",
    "        n_term_p = np.sum(d_beta == i)\n",
    "        n_term = n_term_s + n_term_p\n",
    "\n",
    "\n",
    "        Km_s_idx = np.nonzero(S_s_nz[1, :] == i)\n",
    "        S_s_idx = S_s_nz[0, S_s_nz[1, :] == i] # negate -1 entries\n",
    "\n",
    "        Km_p_idx = np.nonzero(S_p_nz[1, :] == i)\n",
    "        S_p_idx = S_p_nz[0, S_p_nz[1, :] == i]\n",
    "\n",
    "        #S_s_idx = S_s_nz[0, S_s_nz[1, :] == i]\n",
    "\n",
    "        sat_expr.append(           [ (C_alpha @ y_f.value[j, :].flatten())[d_alpha == i] ,\n",
    "                                     (C_beta @ y_r.value[j, :].flatten())[d_beta == i],\n",
    "                                     0,\n",
    "                                     #-1*np.ones(n_lse_terms - n_term + 1)\n",
    "                                   ]\n",
    "                       )\n",
    "        fwd_sat[i] = (np.exp(-S.T[i, S_s_idx] @ y_s.value[j, Km_s_idx].flatten())) # + cfwd.value[i]\n",
    "        back_sat[i] = (np.exp(S.T[i, S_p_idx] @ y_p.value[j, Km_p_idx].flatten())) # + cfwd.value[i]\n",
    "\n",
    "\n",
    "\n",
    "    for i, rxn in enumerate(sat_expr):\n",
    "        s = 0\n",
    "\n",
    "        for term in rxn:\n",
    "            s += np.sum(np.exp(term))\n",
    "\n",
    "        sat[i] = (s)\n",
    "\n",
    "    reconstr = np.exp(cfwd.value) * fwd_sat/sat - np.exp(crev.value) * back_sat/sat\n",
    "    print(reconstr)\n",
    "    reconstructed_vE[j, :] = reconstr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T22:47:14.679671Z",
     "start_time": "2024-04-27T22:47:14.066332Z"
    }
   },
   "id": "514d762f72dad2b7",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "df_vE = pd.DataFrame(vE, columns=Sd.columns, index=[\"Flux set 1\"]).melt(ignore_index=False).reset_index(drop=False)\n",
    "df_vE[\"kind\"] = \"Actual flux\"\n",
    "df_recon = pd.DataFrame(reconstructed_vE, columns=Sd.columns, index=[\"Flux set 1\"]).melt(ignore_index=False).reset_index(drop=False)\n",
    "df_recon[\"kind\"] = \"Reconstructed flux\"\n",
    "\n",
    "df_reconstr_comp = pd.concat([df_vE, df_recon]).reset_index(drop=True)\n",
    "# df_reconstr_comp"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T22:47:30.149355Z",
     "start_time": "2024-04-27T22:47:30.147420Z"
    }
   },
   "id": "970357b6e0df20d6",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "# sort df_reconstr_comp by value\n",
    "df_reconstr_comp = df_reconstr_comp.sort_values(by=\"value\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "sns.catplot(y=\"variable\", x=\"value\", data=df_reconstr_comp, kind=\"bar\", height=100, aspect=0.2)\n",
    "\n",
    "# change x axis to log scale\n",
    "plt.xscale('log')\n",
    "\n",
    "# limit length of y axis labels to 20 characters\n",
    "plt.gca().set_yticklabels([t.get_text()[:20] for t in plt.gca().get_yticklabels()])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T22:47:37.178250Z",
     "start_time": "2024-04-27T22:47:30.150719Z"
    }
   },
   "id": "ac500b6759ac9120",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d10ef3d858d2e28b",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "from convex_kinetics_new import ConvexKineticsNew"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47401ee1ac3e84fb",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "E = ConvexKineticsNew()\n",
    "y_f, y_r, y_s, y_p, y_i, y_a, cfwd, crev, c, Km_s, Km_p, Km_i, Km_a, S_s, S_p, S_i, S_a, \\\n",
    "            met_s_nz, met_p_nz, met_i_nz, met_a_nz, rxn_s_nz, rxn_p_nz, rxn_i_nz, rxn_a_nz, \\\n",
    "            n_rxn, n_met, n_flux_set, S_s_nz, S_p_nz, S = E.set_up_variables(S_matrix=Sd, R_matrix=Sr, flow_data=vE)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "616ccb3db842e3a3",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "C_alpha, C_beta, d_alpha, d_beta = E.construct_binding_matrix(n_rxn, S_s, S_p, S_i, S_a, Sr, met_s_nz, met_p_nz, met_i_nz, met_a_nz, rxn_s_nz, rxn_p_nz, rxn_i_nz, rxn_a_nz)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a91362b271911d9",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "LSE_expr, denom_expr = E.construct_kinetic_objective(vE, n_flux_set, n_rxn, C_alpha, C_beta, d_alpha, d_beta, S_s_nz, S_p_nz, S, y_f, y_r, y_s, y_p, cfwd, crev)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f432cea7a599f271",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "loss = E.create_objective_function(cfwd, crev, c, Km_s, Km_p, Km_i, Km_a, y_s, y_p, LSE_expr, denom_expr)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1879d511ad802b67",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "constr = E.set_parameter_bounds(cfwd, crev, c, Km_s, Km_p, Km_i, Km_a, lower_bound=-12, upper_bound=18)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e78fd83188178f7a",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "problem = E.set_up_problem(loss, constr)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1cba2d8a56c35d9",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "solution = E.solve(problem)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c87be4abc4171e7b",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "solution.value"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a75b5fa2a54490d1",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "reconstructed_vE = np.zeros(vE.shape)\n",
    "\n",
    "for j in range(n_flux_set):\n",
    "    sat_expr = []\n",
    "    fwd_sat = np.zeros(n_rxn)\n",
    "    back_sat = np.zeros(n_rxn)\n",
    "    sat = np.zeros(n_rxn)\n",
    "\n",
    "    for i in range(n_rxn):\n",
    "        # sum terms are separate in logsumexp. one per saturation term (row in C_alpha, C_beta)\n",
    "        n_term_s = np.sum(d_alpha == i)\n",
    "        n_term_p = np.sum(d_beta == i)\n",
    "        n_term = n_term_s + n_term_p\n",
    "\n",
    "\n",
    "        Km_s_idx = np.nonzero(S_s_nz[1, :] == i)\n",
    "        S_s_idx = S_s_nz[0, S_s_nz[1, :] == i] # negate -1 entries\n",
    "\n",
    "        Km_p_idx = np.nonzero(S_p_nz[1, :] == i)\n",
    "        S_p_idx = S_p_nz[0, S_p_nz[1, :] == i]\n",
    "\n",
    "        #S_s_idx = S_s_nz[0, S_s_nz[1, :] == i]\n",
    "\n",
    "        sat_expr.append(           [ (C_alpha @ y_f.value[j, :].flatten())[d_alpha == i] ,\n",
    "                                     (C_beta @ y_r.value[j, :].flatten())[d_beta == i],\n",
    "                                     0,\n",
    "                                     #-1*np.ones(n_lse_terms - n_term + 1)\n",
    "                                   ]\n",
    "                       )\n",
    "        fwd_sat[i] = (np.exp(-S.T[i, S_s_idx] @ y_s.value[j, Km_s_idx].flatten())) # + cfwd.value[i]\n",
    "        back_sat[i] = (np.exp(S.T[i, S_p_idx] @ y_p.value[j, Km_p_idx].flatten())) # + cfwd.value[i]\n",
    "\n",
    "\n",
    "\n",
    "    for i, rxn in enumerate(sat_expr):\n",
    "        s = 0\n",
    "\n",
    "        for term in rxn:\n",
    "            s += np.sum(np.exp(term))\n",
    "\n",
    "        sat[i] = (s)\n",
    "\n",
    "    reconstr = np.exp(cfwd.value) * fwd_sat/sat - np.exp(crev.value) * back_sat/sat\n",
    "    print(reconstr)\n",
    "    reconstructed_vE[j, :] = reconstr"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5487b6b56ef7ad23",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "df_vE = pd.DataFrame(vE, columns=Sd.columns, index=[\"Flux set 1\"]).melt(ignore_index=False).reset_index(drop=False)\n",
    "df_vE[\"kind\"] = \"Actual flux\"\n",
    "df_recon = pd.DataFrame(reconstructed_vE, columns=Sd.columns, index=[\"Flux set 1\"]).melt(ignore_index=False).reset_index(drop=False)\n",
    "df_recon[\"kind\"] = \"Reconstructed flux\"\n",
    "\n",
    "df_reconstr_comp = pd.concat([df_vE, df_recon]).reset_index(drop=True)\n",
    "# df_reconstr_comp\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "769ff89309470bce",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "# sort df_reconstr_comp by value\n",
    "df_reconstr_comp = df_reconstr_comp.sort_values(by=\"value\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "sns.catplot(y=\"variable\", x=\"value\", data=df_reconstr_comp, kind=\"bar\", height=100, aspect=0.5)\n",
    "\n",
    "# change x axis to log scale\n",
    "plt.xscale('log')\n",
    "\n",
    "# limit length of y axis labels to 20 characters\n",
    "plt.gca().set_yticklabels([t.get_text()[:20] for t in plt.gca().get_yticklabels()])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2a64c3bbec0c7c7",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "Sd.loc[:, \"ADCLY-RXN\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "633cd3c6cb49ab6",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "id": "32eae4f190fa0390",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "id": "1be9e15d6a2df996",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "499cc9bc6ec977eb",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
