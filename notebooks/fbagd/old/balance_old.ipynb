{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89c876b4-8497-499f-a413-26ad32cec39e",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from scipy import linalg\n",
    "from scipy.special import logsumexp\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "from inspect import getmembers\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import dill\n",
    "from equilibrator_api import ComponentContribution, Q_, Reaction\n",
    "import requests\n",
    "import xmltodict\n",
    "import pint\n",
    "import cvxpy as cp\n",
    "import itertools\n",
    "import copy\n",
    "\n",
    "sns.set(style='darkgrid', palette='viridis', context='talk')\n",
    "\n",
    "os.chdir(os.path.expanduser('~/vivarium-ecoli'))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "82a34091-b89a-4a8b-b49e-ce86aeab25c6",
   "metadata": {},
   "source": [
    "A + B -E1> C -E2> D\n",
    "\n",
    "B -E3> F\n",
    "\n",
    "A -E4> G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc077b2-8c38-4065-b306-2e91611fd975",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Testing eQuilibrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77f87609-2312-4734-8970-05177c5c3434",
   "metadata": {},
   "source": [
    "cc = ComponentContribution()\n",
    "\n",
    "# optional: changing the aqueous environment parameters\n",
    "cc.p_h = Q_(7.4)\n",
    "cc.p_mg = Q_(3.0)\n",
    "cc.ionic_strength = Q_(\"0.25M\")\n",
    "cc.temperature = Q_(\"298.15K\")\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90008655-107b-487c-b60b-a98b12137dd6",
   "metadata": {},
   "source": [
    "from equilibrator_api import Reaction\n",
    "compound_ids = [\"WATER\", \"ADP\", \"ATP\", \"Pi\"]\n",
    "compound_dict = {cid : cc.get_compound(f\"metacyc.compound:{cid}\") for cid in compound_ids}\n",
    "atpase_reaction = Reaction({\n",
    "    compound_dict[\"ATP\"]: -1,\n",
    "    compound_dict[\"WATER\"]: -1,\n",
    "    compound_dict[\"ADP\"]: 1,\n",
    "    compound_dict[\"Pi\"]: 1,\n",
    "})"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac886c79-121d-4d77-9ba0-eb4b25d19039",
   "metadata": {},
   "source": [
    "standard_dg_prime = cc.standard_dg_prime(atpase_reaction)\n",
    "standard_dg_prime"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6be2265-c9ec-45cf-8b87-8ca2df1376dd",
   "metadata": {},
   "source": [
    "cytoplasmic_p_h = Q_(7.5)\n",
    "cytoplasmic_ionic_strength = Q_(\"250 mM\")\n",
    "periplasmic_p_h = Q_(7.0)\n",
    "periplasmic_ionic_strength = Q_(\"200 mM\")\n",
    "e_potential_difference = Q_(\"0.15 V\")\n",
    "cytoplasmic_reaction = \"bigg.metabolite:pep = bigg.metabolite:g6p + bigg.metabolite:pyr\"\n",
    "periplasmic_reaction = \"bigg.metabolite:glc__D = \"\n",
    "\n",
    "cc = ComponentContribution()\n",
    "cc.p_h = cytoplasmic_p_h\n",
    "cc.ionic_strength = cytoplasmic_ionic_strength\n",
    "standard_dg_prime = cc.multicompartmental_standard_dg_prime(\n",
    "    cc.parse_reaction_formula(cytoplasmic_reaction),\n",
    "    cc.parse_reaction_formula(periplasmic_reaction),\n",
    "    e_potential_difference=e_potential_difference,\n",
    "    p_h_outer=periplasmic_p_h,\n",
    "    ionic_strength_outer=periplasmic_ionic_strength,\n",
    ")\n",
    "\n",
    "print(standard_dg_prime)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c97b6b4-77e2-4ddb-926c-b39f4780811b",
   "metadata": {},
   "source": [
    "cc.get_compound_by_inchi(\"WQZGKKKJIJFFOK-GASJEMHNSA-N\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "fb140010-52ab-4edd-844e-a3645b3d5a41",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Using eQuilibrator to generate equilibrium constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cd11cad-2e4b-4cb7-bec6-6d3e4f7b21bd",
   "metadata": {},
   "source": [
    "s = requests.Session() # create session\n",
    "# Post login credentials to session:\n",
    "s.post('https://websvc.biocyc.org/credentials/login/', data={'email':'cellulararchitect@protonmail.com', 'password':'Cellman0451'})\n",
    "# Issue web service request:\n",
    "r = s.get('https://websvc.biocyc.org/getxml?id=ECOLI:6PFRUCTPHOS-RXN&detail=low&fmt=json')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ceafb21-0bf4-41d7-8e07-c159e8b73302",
   "metadata": {},
   "source": [
    "name = 'F16ALDOLASE-RXN'\n",
    "\n",
    "r = s.get(f'https://websvc.biocyc.org/getxml?id=ECOLI:{name}&detail=low&fmt=json')\n",
    "o = xmltodict.parse(r.content)['ptools-xml']\n",
    "o['Reaction']['enzymatic-reaction']['Enzymatic-Reaction'][0]['@frameid']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "837d6516-fa3c-4b71-ba39-4a98bb9689d3",
   "metadata": {},
   "source": [
    "\n",
    "rxns_names = ['6PFRUCTPHOS-RXN', 'F16ALDOLASE-RXN', '2TRANSKETO-RXN', 'TRIOSEPISOMERIZATION-RXN']\n",
    "\n",
    "rxns_dict = {}\n",
    "stoich_dict = {}\n",
    "regulation_dict = {}\n",
    "\n",
    "for name in rxns_names:\n",
    "    r = s.get(f'https://websvc.biocyc.org/getxml?id=ECOLI:{name}&detail=low&fmt=json')\n",
    "    rxn = xmltodict.parse(r.content)['ptools-xml']\n",
    "\n",
    "    rxn_dict = {}\n",
    "    stoich_loop_dict = {}\n",
    "    regulation_loop_dict = {}\n",
    "    left = rxn['Reaction']['left']\n",
    "    right = rxn['Reaction']['right'] \n",
    "    \n",
    "    # i will know exact complex in model (connected to rxn), but for now will pick random\n",
    "    enz_rxn = rxn['Reaction']['enzymatic-reaction']['Enzymatic-Reaction']\n",
    "    \n",
    "    if type(left) is dict:\n",
    "        left = [left]\n",
    "    \n",
    "    if type(right) is dict:\n",
    "        right = [right]\n",
    "        \n",
    "    if type(enz_rxn) is dict:\n",
    "        enz_rxn = [enz_rxn]\n",
    "    \n",
    "    enz_rxn_id =  enz_rxn[0]['@frameid']\n",
    "    re = s.get(f'https://websvc.biocyc.org/getxml?id=ECOLI:{enz_rxn_id}&detail=high&fmt=json')\n",
    "    oe = xmltodict.parse(re.content)['ptools-xml']['Enzymatic-Reaction']['regulated-by']['Regulation']\n",
    "    \n",
    "    if type(oe) is dict:\n",
    "        oe = [oe]\n",
    "        \n",
    "    # add regulators, target regulator directly with id to get info like irreversible, etc\n",
    "    for regulator in oe:\n",
    "        reg_name = regulator['regulator']['Compound']['@frameid']\n",
    "        reg_type = regulator['mode']['#text']\n",
    "        reg_type = 1 if reg_type == '+' else -1\n",
    "        regulation_loop_dict[reg_name] = reg_type\n",
    "    \n",
    "    for mol in left:\n",
    "        if type(mol) is dict:\n",
    "            cid = mol['Compound']['@frameid']\n",
    "            mol_cc = cc.get_compound(f\"metacyc.compound:{cid}\")\n",
    "            rxn_dict[mol_cc] = -1\n",
    "            stoich_loop_dict[cid] = -1\n",
    "\n",
    "    for mol in right:\n",
    "        if type(mol) is dict:\n",
    "            cid = mol['Compound']['@frameid']\n",
    "            mol_cc = cc.get_compound(f\"metacyc.compound:{cid}\")\n",
    "            rxn_dict[mol_cc] =  1\n",
    "            stoich_loop_dict[cid] = 1\n",
    "    \n",
    "    rxns_dict[name] = Reaction(rxn_dict)\n",
    "    stoich_dict[name] = stoich_loop_dict\n",
    "    regulation_dict[name] = regulation_loop_dict\n",
    "    \n",
    "rxns_dict"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e072326-7492-4a26-adba-02158fcedf0e",
   "metadata": {},
   "source": [
    "(standard_dg_prime, dg_uncertainty) = cc.standard_dg_prime_multi(list(rxns_dict.values()), uncertainty_representation=\"cov\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "748784e9-37fa-4e06-8fa9-88b497816064",
   "metadata": {},
   "source": [
    "standard_dg_prime"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11142f27-1260-4d21-97bc-42c00f4920f6",
   "metadata": {},
   "source": [
    "dg_uncertainty"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "320ca8b3-34c3-4bfe-b43b-e71e5d5685bc",
   "metadata": {},
   "source": [
    "R = 0.008314 # kJ/mol*K\n",
    "T = 298.15 # K"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c217eee-8beb-4c13-82d5-200b12d4add9",
   "metadata": {},
   "source": [
    "dG = standard_dg_prime._magnitude\n",
    "\n",
    "keq = np.exp(-dG/(R*T))\n",
    "keq"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "3a19ac18-e8ce-4653-9976-3946c1227c85",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Calculating set of kinetic parameters with given equilibrium constants and arbitrary fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad0c9880-fd76-40d6-9d15-3bb61f96e3e9",
   "metadata": {},
   "source": [
    "Sd = pd.DataFrame(stoich_dict, dtype=np.int8).fillna(0).astype(np.int8)\n",
    "# Sd = Sd.iloc[0:7, 0:2]\n",
    "\n",
    "n_met = len(Sd.index)\n",
    "n_rxn = len(Sd.columns)\n",
    "\n",
    "Sd"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c82bb78-fff2-4098-9827-6b0d10324746",
   "metadata": {},
   "source": [
    "dG = standard_dg_prime._magnitude\n",
    "\n",
    "keq = np.exp(-dG/(R*T))\n",
    "keq\n",
    "\n",
    "K_eq = np.log(keq)\n",
    "vE = np.array([100, 20, 30, 10])\n",
    "\n",
    "K_eq[vE < 0] = 1/K_eq[vE < 0] \n",
    "\n",
    "lvE = np.log(np.abs(vE))\n",
    "\n",
    "pd.DataFrame(np.array([K_eq, vE]), columns=Sd.columns, index=[\"$K_{eq}$\", \"$v$\"])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "547db931-e727-4c7b-aa7f-a09b80fee71e",
   "metadata": {},
   "source": [
    "# set up variables\n",
    "\n",
    "S = np.array(Sd)\n",
    "S = np.multiply(S, vE/np.abs(vE)).astype(np.int8)\n",
    "S[S == -0] = 0\n",
    "S_s = -np.copy(S)\n",
    "S_p = np.copy(S) #reverse neg sign\n",
    "S_s[S > 0] = 0\n",
    "S_p[S < 0] = 0\n",
    "\n",
    "S_s_nz = np.array(S_s.nonzero())\n",
    "S_p_nz = np.array(S_p.nonzero())\n",
    "\n",
    "# first coordinate, e.g. metabolites w nonzero substrate/product coeff across all reactions. also works as substrate indices. \n",
    "met_s_nz = S_s_nz[0, :]\n",
    "met_p_nz = S_p_nz[0, :]\n",
    "\n",
    "# second coordinate, e.g. reactions indices for those concentrations. works to index substrates as well. \n",
    "rxn_s_nz = S_s_nz[1, :]   \n",
    "rxn_p_nz = S_p_nz[1, :]\n",
    "\n",
    "# one dim is always 2\n",
    "n_Km_s = np.max(met_s_nz.shape) \n",
    "n_Km_p = np.max(met_p_nz.shape)\n",
    "\n",
    "c = cp.Variable(n_met)\n",
    "Km_s = cp.Variable(n_Km_s)\n",
    "Km_p = cp.Variable(n_Km_p)\n",
    "\n",
    "cfwd = cp.Variable(n_rxn)\n",
    "crev = cp.Variable(n_rxn)\n",
    "\n",
    "# define Km positions by nonzero S matrix concentrations\n",
    "y_s = c[met_s_nz] - Km_s\n",
    "y_p = c[met_p_nz] - Km_p\n",
    "\n",
    "# index \n",
    "met_s_nz"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e35cbcbb-7059-41e5-968a-d8997259e1d0",
   "metadata": {},
   "source": [
    "# number of saturation terms for sub, prod\n",
    "n_alpha = np.sum(np.power(2, S_s.sum(axis=0)) - 1)\n",
    "n_beta = np.sum(np.power(2, S_p.sum(axis=0)) - 1)\n",
    "\n",
    "# saturation matrix setup\n",
    "C_alpha = np.zeros([n_alpha, len(met_s_nz)])\n",
    "C_beta = np.zeros([n_beta, len(met_p_nz)])\n",
    "\n",
    "# to separate different reactions saturation terms. \n",
    "d_alpha = np.zeros(n_alpha, dtype=np.int8)\n",
    "d_beta = np.zeros(n_beta, dtype=np.int8)\n",
    "\n",
    "\n",
    "idx = 0\n",
    "\n",
    "for i in range(n_rxn):\n",
    "    \n",
    "    # pick one reaction at a time (get substrate indicies)\n",
    "    idx_cur_rxn = rxn_s_nz == i\n",
    "    \n",
    "    # generates all binary permutations minus the first one since that would result in -1\n",
    "    sat_perm = np.array(list(itertools.product([0, 1], repeat=sum(idx_cur_rxn))))\n",
    "    sat_perm = sat_perm[1:, :]\n",
    "    \n",
    "    r, _ = sat_perm.shape\n",
    "    \n",
    "    # replace zeros with saturation matrix\n",
    "    C_alpha[idx:(idx+r), idx_cur_rxn] = sat_perm\n",
    "    d_alpha[idx:(idx+r)] = i\n",
    "        \n",
    "    idx += r # add row # \n",
    "\n",
    "idx = 0\n",
    "    \n",
    "for i in range(n_rxn):\n",
    "    idx_cur_rxn = rxn_p_nz == i\n",
    "    \n",
    "    sat_perm = np.array(list(itertools.product([0, 1], repeat=sum(idx_cur_rxn))))\n",
    "    sat_perm = sat_perm[1:, :]\n",
    "    \n",
    "    r, _ = sat_perm.shape\n",
    "    \n",
    "    C_beta[idx:(idx+r), idx_cur_rxn] = sat_perm\n",
    "    d_beta[idx:(idx+r)] = i\n",
    "        \n",
    "    idx += r # add row # "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e17e7a68-bcc4-4107-9abd-bc739f79b1ee",
   "metadata": {},
   "source": [
    "C_alpha"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b1839b5-d544-44b6-96dc-3bbf1d217f35",
   "metadata": {},
   "source": [
    "n_lse_terms = np.max(np.power(2, S_s.sum(axis=0)) +  np.power(2, S_p.sum(axis=0)) - 2)\n",
    "LSE_expr = []\n",
    "\n",
    "for i in range(n_rxn):\n",
    "    # sum terms are separate in logsumexp. one per saturation term (row in C_alpha, C_beta)\n",
    "    n_term_s = np.sum(d_alpha == i) \n",
    "    n_term_p = np.sum(d_beta == i)\n",
    "    n_term = n_term_s + n_term_p\n",
    "    \n",
    "    Km_s_idx = np.nonzero(S_s_nz[1, :] == i)\n",
    "    S_s_idx = S_s_nz[0, S_s_nz[1, :] == i] # negate -1 entries\n",
    "    \n",
    "    Km_p_idx = np.nonzero(S_p_nz[1, :] == i)\n",
    "    S_p_idx = S_p_nz[0, S_p_nz[1, :] == i]\n",
    "    \n",
    "    LSE_expr.append(cp.hstack( [ lvE[i] + (C_alpha @ y_s)[d_alpha == i] - cp.multiply(np.ones(n_term_s), -S.T[i, S_s_idx] @ y_s[Km_s_idx]) - cfwd[i],  \n",
    "                                 lvE[i] + (C_beta @ y_p)[d_beta == i] - cp.multiply(np.ones(n_term_p), -S.T[i, S_s_idx] @ y_s[Km_s_idx]) - cfwd[i],\n",
    "                                 lvE[i] + 0 - cp.multiply(np.ones(1), -S.T[i, S_s_idx] @ y_s[Km_s_idx])  - cfwd[i],\n",
    "                                 cp.multiply(np.ones(1), S.T[i, S_p_idx] @ y_p[Km_p_idx])  + crev[i]\n",
    "                                 - cp.multiply(np.ones(1), -S.T[i, S_s_idx] @ y_s[Km_s_idx])  - cfwd[i]\n",
    "                                 #-1*np.ones(n_lse_terms - n_term + 1) \n",
    "                               ]\n",
    "                             )\n",
    "                   )  # remove +1 here, could also have cfwd outside objec. \n",
    "    \n",
    "#LSE_expr = cp.vstack(LSE_expr)\n",
    "LSE_expr"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ea14434-058e-444b-90e8-3d150362571f",
   "metadata": {},
   "source": [
    "l = 0.0000001\n",
    "e = 0.00001\n",
    "f = 0.0000001\n",
    "reg =  cp.sum(cp.hstack([cfwd, crev, c])) + cp.sum(cp.hstack([-Km_s, -Km_p]))# regularization\n",
    "reg2 = cp.norm1(cp.hstack([cfwd, crev, c])) + cp.norm1(cp.hstack([-Km_s, -Km_p]))# regularization\n",
    "reg3 = cp.sum(cp.huber(cp.hstack([y_s, y_p]), 1))\n",
    "#reg3 = cp.norm1(cp.hstack([y_s, y_p])) # take a look at this\n",
    "\n",
    "loss = 0\n",
    "for i in range(n_rxn):\n",
    "    loss += cp.norm2(cp.pos(cp.log_sum_exp(LSE_expr[i])))\n",
    "loss += l * reg \n",
    "loss += e * reg2\n",
    "loss += f * reg3\n",
    "# "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85586d27-113e-4b95-8d70-7dfd2abc644c",
   "metadata": {},
   "source": [
    "haldane = []\n",
    "fwd_flux = []\n",
    "\n",
    "for i, r in enumerate(S.T):\n",
    "    Km_s_idx = np.nonzero(S_s_nz[1, :] == i)\n",
    "    S_s_idx = S_s_nz[0, S_s_nz[1, :] == i] # negate -1 entries\n",
    "    \n",
    "    Km_p_idx = np.nonzero(S_p_nz[1, :] == i)\n",
    "    S_p_idx = S_p_nz[0, S_p_nz[1, :] == i]\n",
    "    \n",
    "    haldane.append(K_eq[i] == cfwd[i] - crev[i] + r[S_p_idx] @ Km_p[Km_p_idx] - (-r[S_s_idx]) @ Km_s[Km_s_idx])  # add minus since s matrix has minus\n",
    "    fwd_flux.append(cfwd[i] + (-r[S_s_idx]) @ y_s[Km_s_idx] - (crev[i] + r[S_p_idx] @ y_p[Km_p_idx])  - (lvE[i])  >= 0)  # add minus since s matrix has minus"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a77dbaef-1995-4496-a867-6891b901e35f",
   "metadata": {},
   "source": [
    "constr = [cp.hstack([cfwd, crev, c, Km_s, Km_p]) >= -12,\n",
    "          cp.hstack([cfwd, crev, c, Km_s, Km_p]) <= 12, cfwd[0] == 7,\n",
    "          ]\n",
    "\n",
    "constr.extend(haldane)\n",
    "constr.extend(fwd_flux)\n",
    "constr.extend([S.T @ c <= K_eq])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b434c2b0-a4d0-43f1-ad56-d98882abafa6",
   "metadata": {},
   "source": [
    "p = cp.Problem(cp.Minimize(loss), constr)\n",
    "p.solve(verbose=True, solver=cp.ECOS)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "5b907a59-21fe-4dd1-9e19-fecf7bb1b1e5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Checking correctness of result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "168df7be-aa37-489b-96bd-70b211f45389",
   "metadata": {},
   "source": [
    "cfwd.value"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "969fd0d0-cb84-4a85-abf9-8e45fac0190e",
   "metadata": {},
   "source": [
    "crev.value"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c06bd43-858a-4a80-87b4-e906682ea9d2",
   "metadata": {},
   "source": [
    "c.value"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "41df70c2-16d4-4cb1-982c-24b36295a53b",
   "metadata": {},
   "source": [
    "Km_s.value"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d2553824-cf7e-4608-9562-48bba6cc213c",
   "metadata": {},
   "source": [
    "Km_p.value"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "2db77294-ce0c-4874-9ac5-954b940ac8d2",
   "metadata": {},
   "source": [
    "## Checking Haldane and fwd/rev flux ratios are satisfied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7bf9b6c8-032f-45db-a73c-188cfbb03736",
   "metadata": {},
   "source": [
    "for i, r in enumerate(S.T):\n",
    "    Km_s_idx = np.nonzero(S_s_nz[1, :] == i)\n",
    "    S_s_idx = S_s_nz[0, S_s_nz[1, :] == i] # negate -1 entries\n",
    "    \n",
    "    Km_p_idx = np.nonzero(S_p_nz[1, :] == i)\n",
    "    S_p_idx = S_p_nz[0, S_p_nz[1, :] == i]\n",
    "    \n",
    "    print(\"haldane\", cfwd.value[i] - crev.value[i] + r[S_p_idx] @ Km_p.value[Km_p_idx] - (-r[S_s_idx]) @ Km_s.value[Km_s_idx] - K_eq[i] )\n",
    "    # print(cfwd.value[i], (-r[S_s_idx]), y_s.value[Km_s_idx], crev.value[i], r[S_p_idx],  y_p.value[Km_p_idx])\n",
    "    print(\"forward\", cfwd.value[i] + (-r[S_s_idx]) @ y_s.value[Km_s_idx] - (crev.value[i] + r[S_p_idx] @ y_p.value[Km_p_idx]))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7dc38b25-e201-4b6b-a275-25561489b194",
   "metadata": {},
   "source": [
    "y_s.value"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d6bf207-f672-4a6f-a191-cc6f0eb648f6",
   "metadata": {},
   "source": [
    "y_p.value"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "6bc8db34-d4c9-4790-bebb-9dbcaa4bb578",
   "metadata": {},
   "source": [
    "## Checking that objective has been minimized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d99f85-252b-4b52-8f21-383c88191a6f",
   "metadata": {},
   "source": [
    "Need to rearrange terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b3655804-a36b-45ea-a80d-275306b72dfe",
   "metadata": {},
   "source": [
    "LSE_expr = []\n",
    "\n",
    "for i in range(n_rxn):\n",
    "    # sum terms are separate in logsumexp. one per saturation term (row in C_alpha, C_beta)\n",
    "    n_term_s = np.sum(d_alpha == i) \n",
    "    n_term_p = np.sum(d_beta == i)\n",
    "    n_term = n_term_s + n_term_p\n",
    "    \n",
    "    Km_s_idx = np.nonzero(S_s_nz[1, :] == i)\n",
    "    S_s_idx = S_s_nz[0, S_s_nz[1, :] == i] # negate -1 entries\n",
    "    \n",
    "    Km_p_idx = np.nonzero(S_p_nz[1, :] == i)\n",
    "    S_p_idx = S_p_nz[0, S_p_nz[1, :] == i]\n",
    "    \n",
    "    \n",
    "    LSE_expr.append(           [ (C_alpha @ y_s.value)[d_alpha == i] - np.multiply(np.ones(n_term_s), -S.T[i, S_s_idx] @ y_s.value[Km_s_idx]) - cfwd.value[i],  \n",
    "                                 (C_beta @ y_p.value)[d_beta == i] - np.multiply(np.ones(n_term_p), -S.T[i, S_s_idx] @ y_s.value[Km_s_idx]) - cfwd.value[i],\n",
    "                                 0 - np.multiply(np.ones(1), -S.T[i, S_s_idx] @ y_s.value[Km_s_idx])  - cfwd.value[i],\n",
    "                                 np.multiply(np.ones(1), S.T[i, S_p_idx] @ y_p.value[Km_p_idx])  + crev.value[i]\n",
    "                                 - np.multiply(np.ones(1), -S.T[i, S_s_idx] @ y_s.value[Km_s_idx])  - cfwd.value[i]\n",
    "                                 #-1*np.ones(n_lse_terms - n_term + 1) \n",
    "                                 #-1*np.ones(n_lse_terms - n_term + 1) \n",
    "                               ]\n",
    "                   )\n",
    "    \n",
    "\n",
    "est = np.zeros(4)    \n",
    "\n",
    "for i, rxn in enumerate(LSE_expr):\n",
    "    s = 0\n",
    "    \n",
    "    for term in rxn:\n",
    "        s += np.sum(np.exp(term))\n",
    "        \n",
    "    est[i] = np.log(s)\n",
    "    \n",
    "\n",
    "# est is obj. \n",
    "print(np.array([np.exp(-est),np.exp(lvE)]))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "d282711e-4f51-401b-b575-0e1ba82d7150",
   "metadata": {},
   "source": [
    "## How closely does the objective match our target kcats?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b87caa09-14b9-44b4-b4da-647b62e5f898",
   "metadata": {},
   "source": [
    "print(np.array([np.exp(-est),np.exp(lvE)]))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "88c231fb-31bf-4347-ad2d-8b9495c745d9",
   "metadata": {},
   "source": [
    "Remarkable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87868215-a91b-442e-b3f3-13121677d5f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## What do fluxes with reverse flow look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "f148ad8b-a086-440b-9cf3-304bc244e77b",
   "metadata": {},
   "source": [
    "sat_expr = []\n",
    "fwd_sat = np.zeros(n_rxn)\n",
    "back_sat = np.zeros(n_rxn)\n",
    "sat = np.zeros(n_rxn)\n",
    "\n",
    "for i in range(n_rxn):\n",
    "    # sum terms are separate in logsumexp. one per saturation term (row in C_alpha, C_beta)\n",
    "    n_term_s = np.sum(d_alpha == i) \n",
    "    n_term_p = np.sum(d_beta == i)\n",
    "    n_term = n_term_s + n_term_p\n",
    "    \n",
    "    \n",
    "    Km_s_idx = np.nonzero(S_s_nz[1, :] == i)\n",
    "    S_s_idx = S_s_nz[0, S_s_nz[1, :] == i] # negate -1 entries\n",
    "    \n",
    "    Km_p_idx = np.nonzero(S_p_nz[1, :] == i)\n",
    "    S_p_idx = S_p_nz[0, S_p_nz[1, :] == i]\n",
    "    \n",
    "    #S_s_idx = S_s_nz[0, S_s_nz[1, :] == i]\n",
    "    \n",
    "    sat_expr.append(           [ (C_alpha @ y_s.value)[d_alpha == i] ,  \n",
    "                                 (C_beta @ y_p.value)[d_beta == i],\n",
    "                                 0,\n",
    "                                 #-1*np.ones(n_lse_terms - n_term + 1) \n",
    "                               ]\n",
    "                   )\n",
    "    fwd_sat[i] = (np.exp(-S.T[i, S_s_idx] @ y_s.value[Km_s_idx])) # + cfwd.value[i]\n",
    "    back_sat[i] = (np.exp(S.T[i, S_p_idx] @ y_p.value[Km_p_idx])) # + cfwd.value[i]\n",
    "    \n",
    "    \n",
    "\n",
    "for i, rxn in enumerate(sat_expr):\n",
    "    s = 0\n",
    "    \n",
    "    for term in rxn:\n",
    "        s += np.sum(np.exp(term))\n",
    "        \n",
    "    sat[i] = (s)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "2ec2a988-ad4a-45a1-afda-4006da2b2264",
   "metadata": {},
   "source": [
    "fwd_sat/sat"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "52799b3c-90c6-49b3-b13b-ccf121d34636",
   "metadata": {},
   "source": [
    "back_sat/sat"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "01dc4162-6b77-4dd2-9bef-333d4f05aed6",
   "metadata": {},
   "source": [
    "np.exp(cfwd.value) * fwd_sat/sat "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "a721b1a5-a03f-4cb7-a96a-1959c053bf39",
   "metadata": {},
   "source": [
    "np.exp(cfwd.value) * fwd_sat/sat - np.exp(crev.value) * back_sat/sat"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "e606bbac-e82b-4853-a474-d6dde1be1ac5",
   "metadata": {},
   "source": [
    "np.exp(crev.value) * back_sat/sat"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "6bcd27a4-3909-4845-b18a-ddcd03197ca7",
   "metadata": {},
   "source": [
    "print('Substrate Km:', [f'{val:.3f}' for val in np.exp(Km_s.value)])\n",
    "print('Product Km:', [f'{val:.3f}' for val in np.exp(Km_p.value)])\n",
    "print('Fwd kcat:', [f'{val:.3f}' for val in np.exp(cfwd.value)])\n",
    "print('Rev kcat:', [f'{val:.3f}' for val in np.exp(crev.value)])\n",
    "print('Concentrations:', [f'{val:.3f}' for val in np.exp(c.value)])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "760251b4-5b1d-47dc-8255-acacc9120c71",
   "metadata": {},
   "source": [
    "reconst_df = pd.DataFrame({\"Reaction\": Sd.columns, \"True fluxes\": np.abs(vE), \"Estimated fluxes\": np.exp(cfwd.value) * fwd_sat/sat - np.exp(crev.value) * back_sat/sat})\n",
    "reconst_df = reconst_df.melt(id_vars=\"Reaction\")\n",
    "reconst_df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "ccb402e5-4c55-4e57-8b6c-6c6eb77452d8",
   "metadata": {},
   "source": [
    "sns.catplot(y=\"Reaction\", hue=\"variable\", x=\"value\", data=reconst_df, kind=\"bar\", aspect=2.5)\n",
    "plt.savefig(\"notebooks/fbagd/figures/reconstruction.png\", dpi=300)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "3ffdf47a-d0f6-4e70-83c5-f46f50562a94",
   "metadata": {},
   "source": [
    "np.exp(cfwd.value) * fwd_sat/sat - np.exp(crev.value) * back_sat/sat"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "6f40a66b-cdad-426d-9584-22647d984c5b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Including inhibition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4bef04-60ec-4e63-af96-b1db319e0a3c",
   "metadata": {},
   "source": [
    "## I'm excluding some of the first operations as they are the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "7e6459f6-81f0-4ac0-ac67-fcfe43974a38",
   "metadata": {},
   "source": [
    "dG = standard_dg_prime._magnitude\n",
    "\n",
    "keq = np.exp(-dG/(R*T))\n",
    "keq\n",
    "\n",
    "K_eq = np.log(keq)\n",
    "vE = np.array([100, -20, 30, 10])\n",
    "\n",
    "K_eq[vE < 0] = -K_eq[vE < 0] \n",
    "\n",
    "lvE = np.log(np.abs(vE))\n",
    "\n",
    "pd.DataFrame(np.array([K_eq, vE]), columns=Sd.columns, index=[\"$K_{eq}$\", \"$v$\"])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "f76ea927-4576-4eb5-b24e-c3dcdc934ff2",
   "metadata": {
    "tags": []
   },
   "source": [
    "Sd"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "59f138a7-df55-4436-8c87-9e799036d0e0",
   "metadata": {},
   "source": [
    "Adding regulation dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "760bee51-984c-4f98-91fd-788113ce0d86",
   "metadata": {},
   "source": [
    "Sr_min = pd.DataFrame(regulation_dict).fillna(0).astype(np.int8)\n",
    "\n",
    "Sr = Sd.copy()\n",
    "Sr.loc[:,:] = 0\n",
    "Sr.loc[Sd.index.intersection(Sr_min.index), :] = Sr_min.loc[Sd.index.intersection(Sr_min.index), :]\n",
    "Sr"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "5bf8a342-931a-45a0-b57b-d4f0c50c4e20",
   "metadata": {},
   "source": [
    "# set up variables\n",
    "\n",
    "S = np.array(Sd)\n",
    "S = np.multiply(S, vE/np.abs(vE)).astype(np.int8)\n",
    "S[S == -0] = 0\n",
    "S_s = -np.copy(S)\n",
    "S_p = np.copy(S) #reverse neg sign\n",
    "S_s[S > 0] = 0\n",
    "S_p[S < 0] = 0\n",
    "S_i = np.copy(np.array(Sr) == -1)\n",
    "S_a = np.copy(np.array(Sr) == 1)\n",
    "\n",
    "\n",
    "S_s_nz = np.array(S_s.nonzero())\n",
    "S_p_nz = np.array(S_p.nonzero())\n",
    "S_i_nz = np.array(S_i.nonzero())\n",
    "S_a_nz = np.array(S_a.nonzero())\n",
    "\n",
    "# TODO Refactor all the below lines as one liners \n",
    "# first coordinate, e.g. metabolites w nonzero substrate/product coeff across all reactions. also works as substrate indices. \n",
    "met_s_nz = S_s_nz[0, :]\n",
    "met_p_nz = S_p_nz[0, :]\n",
    "met_i_nz = S_i_nz[0, :]\n",
    "met_a_nz = S_a_nz[0, :]\n",
    "\n",
    "# second coordinate, e.g. reactions indices for those concentrations. works to index substrates as well. \n",
    "rxn_s_nz = S_s_nz[1, :]   \n",
    "rxn_p_nz = S_p_nz[1, :]\n",
    "rxn_i_nz = S_i_nz[1, :]\n",
    "rxn_a_nz = S_a_nz[1, :]\n",
    "\n",
    "# one dim is always 2\n",
    "n_Km_s = np.max(met_s_nz.shape) \n",
    "n_Km_p = np.max(met_p_nz.shape)\n",
    "n_Km_i = np.max(met_i_nz.shape) \n",
    "n_Km_a = np.max(met_a_nz.shape)\n",
    "\n",
    "c = cp.Variable(n_met)\n",
    "Km_s = cp.Variable(n_Km_s)\n",
    "Km_p = cp.Variable(n_Km_p)\n",
    "Km_i = cp.Variable(n_Km_i) if n_Km_i else None\n",
    "Km_a = cp.Variable(n_Km_a) if n_Km_a else None\n",
    "\n",
    "cfwd = cp.Variable(n_rxn)\n",
    "crev = cp.Variable(n_rxn)\n",
    "\n",
    "# define Km positions by nonzero S matrix concentrations. Activation is reverse val of inhibition. \n",
    "y_s = c[met_s_nz] - Km_s\n",
    "y_p = c[met_p_nz] - Km_p\n",
    "y_i = c[met_i_nz] - Km_i if n_Km_i else None\n",
    "y_a = -(c[met_a_nz] - Km_a) if n_Km_a else None\n",
    "\n",
    "# saturation stacks\n",
    "if n_Km_i and n_Km_a:\n",
    "    y_f = cp.hstack((y_s, y_i, y_a))\n",
    "    y_r = cp.hstack((y_p, y_i, y_a))\n",
    "elif n_Km_i:\n",
    "    y_f = cp.hstack((y_s, y_i))\n",
    "    y_r = cp.hstack((y_p, y_i))\n",
    "elif n_Km_a:\n",
    "    y_f = cp.hstack((y_s, y_a))\n",
    "    y_r = cp.hstack((y_p, y_a))\n",
    "else:\n",
    "    y_f = y_s\n",
    "    y_r = y_p"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "627f247b-9c2f-4648-8798-4703fbc261e8",
   "metadata": {},
   "source": [
    "S"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "7e415219-5e67-4cbd-9e87-f7c858c1a648",
   "metadata": {},
   "source": [
    "# number of saturation terms for sub, prod\n",
    "S_s_comb = np.concatenate((S_s, S_i, S_a), axis=0)\n",
    "S_p_comb = np.concatenate((S_p, S_i, S_a), axis=0)\n",
    "n_alpha = np.sum(np.power(2, S_s_comb.sum(axis=0)) - 1)\n",
    "n_beta = np.sum(np.power(2, S_p_comb.sum(axis=0)) - 1)\n",
    "\n",
    "# saturation matrix setup, first sub, then inhib, then act. \n",
    "C_alpha = np.zeros([n_alpha, len(met_s_nz) + len(met_i_nz) + len(met_a_nz)])\n",
    "C_beta = np.zeros([n_beta, len(met_p_nz) + len(met_i_nz) + len(met_a_nz)])\n",
    "\n",
    "# to separate different reactions saturation terms to their individual reaction equations. \n",
    "d_alpha = np.zeros(n_alpha, dtype=np.int8)\n",
    "d_beta = np.zeros(n_beta, dtype=np.int8)\n",
    "\n",
    "\n",
    "idx = 0\n",
    "\n",
    "for i in range(n_rxn):\n",
    "    \n",
    "    # pick one reaction at a time (get substrate indicies)\n",
    "    #idx_cur_rxn = rxn_s_nz == i\n",
    "    idx_cur_rxn = np.concatenate((rxn_s_nz == i, rxn_i_nz == i, rxn_a_nz == i))\n",
    "    \n",
    "    # generates all binary permutations minus the first one since that would result in -1\n",
    "    sat_perm = np.array(list(itertools.product([0, 1], repeat=sum(idx_cur_rxn))))\n",
    "    sat_perm = sat_perm[1:, :]\n",
    "    \n",
    "    r, _ = sat_perm.shape\n",
    "    \n",
    "    # replace zeros with saturation matrix\n",
    "    C_alpha[idx:(idx+r), idx_cur_rxn] = sat_perm\n",
    "    d_alpha[idx:(idx+r)] = i\n",
    "        \n",
    "    idx += r # add row # \n",
    "\n",
    "idx = 0\n",
    "    \n",
    "for i in range(n_rxn):\n",
    "    idx_cur_rxn = np.concatenate((rxn_p_nz == i, rxn_i_nz == i, rxn_a_nz == i))\n",
    "    \n",
    "    sat_perm = np.array(list(itertools.product([0, 1], repeat=sum(idx_cur_rxn))))\n",
    "    sat_perm = sat_perm[1:, :]\n",
    "    \n",
    "    r, _ = sat_perm.shape\n",
    "    \n",
    "    C_beta[idx:(idx+r), idx_cur_rxn] = sat_perm\n",
    "    d_beta[idx:(idx+r)] = i\n",
    "        \n",
    "    idx += r # add row # "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "be7e4a69-a3da-4811-b363-bd748ea66e3c",
   "metadata": {},
   "source": [
    "n_lse_terms = np.max(np.power(2, S_s.sum(axis=0)) +  np.power(2, S_p.sum(axis=0)) - 2)\n",
    "LSE_expr = []\n",
    "\n",
    "for i in range(n_rxn):\n",
    "    # sum terms are separate in logsumexp. one per saturation term (row in C_alpha, C_beta)\n",
    "    n_term_s = np.sum(d_alpha == i) \n",
    "    n_term_p = np.sum(d_beta == i)\n",
    "    n_term = n_term_s + n_term_p\n",
    "    \n",
    "    Km_s_idx = np.nonzero(S_s_nz[1, :] == i)\n",
    "    S_s_idx = S_s_nz[0, S_s_nz[1, :] == i] # negate -1 entries\n",
    "    \n",
    "    Km_p_idx = np.nonzero(S_p_nz[1, :] == i)\n",
    "    S_p_idx = S_p_nz[0, S_p_nz[1, :] == i]\n",
    "    \n",
    "    LSE_expr.append(cp.hstack( [ lvE[i] + (C_alpha @ y_f)[d_alpha == i] - cp.multiply(np.ones(n_term_s), - S.T[i, S_s_idx] @ y_s[Km_s_idx]) - cfwd[i],  \n",
    "                                 lvE[i] + (C_beta @ y_r)[d_beta == i] - cp.multiply(np.ones(n_term_p), - S.T[i, S_s_idx] @ y_s[Km_s_idx]) - cfwd[i],\n",
    "                                 lvE[i] + 0 - cp.multiply(np.ones(1), -S.T[i, S_s_idx] @ y_s[Km_s_idx])  - cfwd[i],\n",
    "                                 cp.multiply(np.ones(1), S.T[i, S_p_idx] @ y_p[Km_p_idx])  + crev[i]\n",
    "                                 - cp.multiply(np.ones(1), -S.T[i, S_s_idx] @ y_s[Km_s_idx])  - cfwd[i]\n",
    "                                 #-1*np.ones(n_lse_terms - n_term + 1) \n",
    "                               ]\n",
    "                             )\n",
    "                   )  # remove +1 here, could also have cfwd outside objec. \n",
    "    \n",
    "#LSE_expr = cp.vstack(LSE_expr)\n",
    "LSE_expr"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "659d1c8d-3aef-4b75-a77e-76efc4d006a0",
   "metadata": {},
   "source": [
    "l = 0.0000001\n",
    "e = 0.00001\n",
    "f = 0.0000001\n",
    "reg =  cp.sum(cp.hstack([cfwd, crev, c])) + cp.sum(cp.hstack([-Km_s, -Km_p]))# regularization\n",
    "reg2 = cp.norm1(cp.hstack([cfwd, crev, c])) + cp.norm1(cp.hstack([-Km_s, -Km_p]))# regularization\n",
    "reg3 = cp.sum(cp.huber(cp.hstack([y_s, y_p]), 1))\n",
    "\n",
    "if n_Km_i:\n",
    "    reg += cp.sum(cp.hstack([-Km_i]))\n",
    "if n_Km_a:\n",
    "    reg += cp.sum(cp.hstack([-Km_a]))\n",
    "#reg3 = cp.norm1(cp.hstack([y_s, y_p])) # take a look at this\n",
    "\n",
    "loss = 0\n",
    "for i in range(n_rxn):\n",
    "    loss += cp.norm2(cp.pos(cp.log_sum_exp(LSE_expr[i])))\n",
    "loss += l * reg \n",
    "loss += e * reg2\n",
    "loss += f * reg3\n",
    "# "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "004cbea2-33e3-4128-bba3-2aece5cca605",
   "metadata": {},
   "source": [
    "haldane = []\n",
    "fwd_flux = []\n",
    "\n",
    "for i, r in enumerate(S.T):\n",
    "    Km_s_idx = np.nonzero(S_s_nz[1, :] == i)\n",
    "    S_s_idx = S_s_nz[0, S_s_nz[1, :] == i] # negate -1 entries\n",
    "    \n",
    "    Km_p_idx = np.nonzero(S_p_nz[1, :] == i)\n",
    "    S_p_idx = S_p_nz[0, S_p_nz[1, :] == i]\n",
    "    \n",
    "    haldane.append(K_eq[i] == cfwd[i] - crev[i] + r[S_p_idx] @ Km_p[Km_p_idx] - (-r[S_s_idx]) @ Km_s[Km_s_idx])  # add minus since s matrix has minus\n",
    "    fwd_flux.append(cfwd[i] + (-r[S_s_idx]) @ y_s[Km_s_idx] - (crev[i] + r[S_p_idx] @ y_p[Km_p_idx])  >= 0)  # add minus since s matrix has minus"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "c2ec7761-6d1a-4e44-b798-bffab58cdc31",
   "metadata": {},
   "source": [
    "constr = [cp.hstack([cfwd, crev, c, Km_s, Km_p]) >= -12,\n",
    "          cp.hstack([cfwd, crev, c, Km_s, Km_p]) <= 12, \n",
    "          ]\n",
    "\n",
    "if n_Km_i:\n",
    "    constr.extend([Km_i >= -12, Km_i <= 12])\n",
    "if n_Km_a:\n",
    "    constr.extend([Km_a >= -12, Km_a <= 12])\n",
    "\n",
    "constr.extend(haldane)\n",
    "constr.extend(fwd_flux)\n",
    "constr.extend([S.T @ c <= K_eq])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "1aacba37-98cb-40f8-9d5f-6f9a053acbbc",
   "metadata": {},
   "source": [
    "p = cp.Problem(cp.Minimize(loss), constr)\n",
    "p.solve(verbose=False, solver=cp.ECOS)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "b3ae86a8-96d3-4c20-902b-133cc9ae4b6d",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "6d9cb71d-17e6-40bf-b57a-f6f1201418bb",
   "metadata": {},
   "source": [
    "print('Substrate Km:', [f'{val:.3f}' for val in np.exp(Km_s.value)])\n",
    "print('Product Km:', [f'{val:.3f}' for val in np.exp(Km_p.value)])\n",
    "print('Fwd kcat:', [f'{val:.3f}' for val in np.exp(cfwd.value)])\n",
    "print('Rev kcat:', [f'{val:.3f}' for val in np.exp(crev.value)])\n",
    "print('Concentrations:', [f'{val:.3f}' for val in np.exp(c.value)])\n",
    "\n",
    "if n_Km_i:\n",
    "    print('Inhibition Km:', [f'{val:.3f}' for val in np.exp(Km_i.value)])\n",
    "if n_Km_a:\n",
    "    print('Activation Km:', [f'{val:.3f}' for val in np.exp(Km_a.value)])"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "fca387c4-48f6-4284-bd4c-58dd5a9df98f",
   "metadata": {},
   "source": [
    "## Check equilibrium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "85dc0a11-f3da-4a5d-9fc8-bb8dbf1b27ca",
   "metadata": {},
   "source": [
    "S.T @ c.value <= K_eq"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "71ee10ab-ffe5-4b4b-b49c-369f66046a91",
   "metadata": {},
   "source": [
    "S.T @ c.value"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "f64070ee-086b-449c-906a-2709e8aa0e23",
   "metadata": {},
   "source": [
    "K_eq"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "dec12056-d8b5-41ca-baa7-422b6f0fac38",
   "metadata": {},
   "source": [
    "## Check flux reconstruction with inhibition/activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "7d487012-6835-43b4-b1b3-9510c066b502",
   "metadata": {},
   "source": [
    "sat_expr = []\n",
    "fwd_sat = np.zeros(n_rxn)\n",
    "back_sat = np.zeros(n_rxn)\n",
    "sat = np.zeros(n_rxn)\n",
    "\n",
    "for i in range(n_rxn):\n",
    "    # sum terms are separate in logsumexp. one per saturation term (row in C_alpha, C_beta)\n",
    "    n_term_s = np.sum(d_alpha == i) \n",
    "    n_term_p = np.sum(d_beta == i)\n",
    "    n_term = n_term_s + n_term_p\n",
    "    \n",
    "    \n",
    "    Km_s_idx = np.nonzero(S_s_nz[1, :] == i)\n",
    "    S_s_idx = S_s_nz[0, S_s_nz[1, :] == i] # negate -1 entries\n",
    "    \n",
    "    Km_p_idx = np.nonzero(S_p_nz[1, :] == i)\n",
    "    S_p_idx = S_p_nz[0, S_p_nz[1, :] == i]\n",
    "    \n",
    "    #S_s_idx = S_s_nz[0, S_s_nz[1, :] == i]\n",
    "    \n",
    "    sat_expr.append(           [ (C_alpha @ y_f.value)[d_alpha == i] ,  \n",
    "                                 (C_beta @ y_r.value)[d_beta == i],\n",
    "                                 0,\n",
    "                                 #-1*np.ones(n_lse_terms - n_term + 1) \n",
    "                               ]\n",
    "                   )\n",
    "    fwd_sat[i] = (np.exp(-S.T[i, S_s_idx] @ y_s.value[Km_s_idx])) # + cfwd.value[i]\n",
    "    back_sat[i] = (np.exp(S.T[i, S_p_idx] @ y_p.value[Km_p_idx])) # + cfwd.value[i]\n",
    "    \n",
    "    \n",
    "\n",
    "for i, rxn in enumerate(sat_expr):\n",
    "    s = 0\n",
    "    \n",
    "    for term in rxn:\n",
    "        s += np.sum(np.exp(term))\n",
    "        \n",
    "    sat[i] = (s)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "137a8d97-36b6-47d6-89d8-5cc67da64f6f",
   "metadata": {},
   "source": [
    "np.exp(cfwd.value) * fwd_sat/sat - np.exp(crev.value) * back_sat/sat"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "876a78e3-8871-4951-a94f-176508dec699",
   "metadata": {},
   "source": [
    "Km_a.value"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b5972830-a1cf-4623-8e47-89ecea910982",
   "metadata": {},
   "source": [
    "Both enzymes have a much higher concentration than K_a, e.g. both are activated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "0f94615b-1962-4fb2-92c9-53f159fc4f22",
   "metadata": {},
   "source": [
    "np.exp(-y_a.value)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "6269f04e-fb7e-459b-b2fd-091c89a20936",
   "metadata": {},
   "source": [
    "About 99%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44701e69-9a4b-4681-82e2-250c1804ba5c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Reworking directionality to just rearrange terms, so we can add multiple substrate sets. One flux set to compare to previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "78ba688c-c5cd-4c30-89c5-85c57321b036",
   "metadata": {},
   "source": [
    "K_eq = np.log(keq)\n",
    "#vE = np.array([100, 20, -30, -10])\n",
    "\n",
    "# K_eq[vE < 0] = 1/K_eq[vE < 0] \n",
    "\n",
    "lvE = np.log(np.abs(vE))\n",
    "pd.DataFrame(np.array([K_eq, vE, np.sign(vE, dtype=np.int8)]), columns=Sd.columns, index=[\"$K_{eq}$\", \"$v$\", \"sign\"])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "0fa1b725-8024-4208-a4ba-c10ec77f809c",
   "metadata": {},
   "source": [
    "# set up variables\n",
    "\n",
    "S = np.array(Sd)\n",
    "# S = np.multiply(S, vE/np.abs(vE)).astype(np.int8) # flips signs on reverse reactions, not needed\n",
    "# S[S == -0] = 0\n",
    "S_s = -np.copy(S) # reverse neg sign\n",
    "S_p = np.copy(S) \n",
    "S_s[S > 0] = 0 # zeros products\n",
    "S_p[S < 0] = 0 # zeros substrates\n",
    "S_i = np.copy(np.array(Sr) == -1) # reaction direction does not matter\n",
    "S_a = np.copy(np.array(Sr) == 1)\n",
    "\n",
    "\n",
    "S_s_nz = np.array(S_s.nonzero())\n",
    "S_p_nz = np.array(S_p.nonzero())\n",
    "S_i_nz = np.array(S_i.nonzero())\n",
    "S_a_nz = np.array(S_a.nonzero())\n",
    "\n",
    "# TODO Refactor all the below lines as one liners \n",
    "# first coordinate, e.g. metabolites w nonzero substrate/product coeff across all reactions. also works as substrate indices. \n",
    "met_s_nz = S_s_nz[0, :]\n",
    "met_p_nz = S_p_nz[0, :]\n",
    "met_i_nz = S_i_nz[0, :]\n",
    "met_a_nz = S_a_nz[0, :]\n",
    "\n",
    "# second coordinate, e.g. reactions indices for those concentrations. works to index substrates as well. \n",
    "rxn_s_nz = S_s_nz[1, :]   \n",
    "rxn_p_nz = S_p_nz[1, :]\n",
    "rxn_i_nz = S_i_nz[1, :]\n",
    "rxn_a_nz = S_a_nz[1, :]\n",
    "\n",
    "# one dim is always 2\n",
    "n_Km_s = np.max(met_s_nz.shape) \n",
    "n_Km_p = np.max(met_p_nz.shape)\n",
    "n_Km_i = np.max(met_i_nz.shape) \n",
    "n_Km_a = np.max(met_a_nz.shape)\n",
    "\n",
    "c = cp.Variable(n_met)\n",
    "Km_s = cp.Variable(n_Km_s)\n",
    "Km_p = cp.Variable(n_Km_p)\n",
    "Km_i = cp.Variable(n_Km_i) if n_Km_i else None\n",
    "Km_a = cp.Variable(n_Km_a) if n_Km_a else None\n",
    "\n",
    "cfwd = cp.Variable(n_rxn)\n",
    "crev = cp.Variable(n_rxn)\n",
    "\n",
    "# define Km positions by nonzero S matrix concentrations. Activation is reverse val of inhibition. \n",
    "y_s = c[met_s_nz] - Km_s\n",
    "y_p = c[met_p_nz] - Km_p\n",
    "y_i = c[met_i_nz] - Km_i if n_Km_i else None\n",
    "y_a = -(c[met_a_nz] - Km_a) if n_Km_a else None\n",
    "\n",
    "# saturation stacks\n",
    "if n_Km_i and n_Km_a:\n",
    "    y_f = cp.hstack((y_s, y_i, y_a))\n",
    "    y_r = cp.hstack((y_p, y_i, y_a))\n",
    "elif n_Km_i:\n",
    "    y_f = cp.hstack((y_s, y_i))\n",
    "    y_r = cp.hstack((y_p, y_i))\n",
    "elif n_Km_a:\n",
    "    y_f = cp.hstack((y_s, y_a))\n",
    "    y_r = cp.hstack((y_p, y_a))\n",
    "else:\n",
    "    y_f = y_s\n",
    "    y_r = y_p"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "84de423e-67c2-402c-b7b4-3c7007e205cf",
   "metadata": {},
   "source": [
    "S"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "f2c7b291-51aa-44db-bb1a-d9cdb22d2090",
   "metadata": {},
   "source": [
    "# number of saturation terms for sub, prod\n",
    "S_s_comb = np.concatenate((S_s, S_i, S_a), axis=0)\n",
    "S_p_comb = np.concatenate((S_p, S_i, S_a), axis=0)\n",
    "n_alpha = np.sum(np.power(2, S_s_comb.sum(axis=0)) - 1)\n",
    "n_beta = np.sum(np.power(2, S_p_comb.sum(axis=0)) - 1)\n",
    "\n",
    "# saturation matrix setup, first sub, then inhib, then act. \n",
    "C_alpha = np.zeros([n_alpha, len(met_s_nz) + len(met_i_nz) + len(met_a_nz)])\n",
    "C_beta = np.zeros([n_beta, len(met_p_nz) + len(met_i_nz) + len(met_a_nz)])\n",
    "\n",
    "# to separate different reactions saturation terms to their individual reaction equations. \n",
    "d_alpha = np.zeros(n_alpha, dtype=np.int8)\n",
    "d_beta = np.zeros(n_beta, dtype=np.int8)\n",
    "\n",
    "\n",
    "idx = 0\n",
    "\n",
    "for i in range(n_rxn):\n",
    "    \n",
    "    # pick one reaction at a time (get substrate indicies)\n",
    "    #idx_cur_rxn = rxn_s_nz == i\n",
    "    idx_cur_rxn = np.concatenate((rxn_s_nz == i, rxn_i_nz == i, rxn_a_nz == i))\n",
    "    \n",
    "    # generates all binary permutations minus the first one since that would result in -1\n",
    "    sat_perm = np.array(list(itertools.product([0, 1], repeat=sum(idx_cur_rxn))))\n",
    "    sat_perm = sat_perm[1:, :]\n",
    "    \n",
    "    r, _ = sat_perm.shape\n",
    "    \n",
    "    # replace zeros with saturation matrix\n",
    "    C_alpha[idx:(idx+r), idx_cur_rxn] = sat_perm\n",
    "    d_alpha[idx:(idx+r)] = i\n",
    "        \n",
    "    idx += r # add row # \n",
    "\n",
    "idx = 0\n",
    "    \n",
    "for i in range(n_rxn):\n",
    "    idx_cur_rxn = np.concatenate((rxn_p_nz == i, rxn_i_nz == i, rxn_a_nz == i))\n",
    "    \n",
    "    sat_perm = np.array(list(itertools.product([0, 1], repeat=sum(idx_cur_rxn))))\n",
    "    sat_perm = sat_perm[1:, :]\n",
    "    \n",
    "    r, _ = sat_perm.shape\n",
    "    \n",
    "    C_beta[idx:(idx+r), idx_cur_rxn] = sat_perm\n",
    "    d_beta[idx:(idx+r)] = i\n",
    "        \n",
    "    idx += r # add row # "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "8f9bc9b7-de93-4c01-8ff5-89199d4dfd8a",
   "metadata": {},
   "source": [
    "n_lse_terms = np.max(np.power(2, S_s.sum(axis=0)) +  np.power(2, S_p.sum(axis=0)) - 2)\n",
    "LSE_expr = []\n",
    "\n",
    "sign = np.sign(vE)\n",
    "lvE = np.log(sign * vE)\n",
    "\n",
    "for i in range(n_rxn):\n",
    "    # sum terms are separate in logsumexp. one per saturation term (row in C_alpha, C_beta)\n",
    "    \n",
    "    n_term_s = np.sum(d_alpha == i) \n",
    "    n_term_p = np.sum(d_beta == i)\n",
    "    n_term = n_term_s + n_term_p\n",
    "    \n",
    "    Km_s_idx = np.nonzero(S_s_nz[1, :] == i)\n",
    "    S_s_idx = S_s_nz[0, S_s_nz[1, :] == i] # negate -1 entries\n",
    "    \n",
    "    Km_p_idx = np.nonzero(S_p_nz[1, :] == i)\n",
    "    S_p_idx = S_p_nz[0, S_p_nz[1, :] == i]\n",
    "    \n",
    "    if sign[i] == 1:\n",
    "        LSE_expr.append(cp.hstack( [ lvE[i] + (C_alpha @ y_f)[d_alpha == i] - cp.multiply(np.ones(n_term_s), - S.T[i, S_s_idx] @ y_s[Km_s_idx]) - cfwd[i],  \n",
    "                                     lvE[i] + (C_beta @ y_r)[d_beta == i] - cp.multiply(np.ones(n_term_p), - S.T[i, S_s_idx] @ y_s[Km_s_idx]) - cfwd[i],\n",
    "                                     lvE[i] + 0 - cp.multiply(np.ones(1), -S.T[i, S_s_idx] @ y_s[Km_s_idx])  - cfwd[i],\n",
    "                                     cp.multiply(np.ones(1), S.T[i, S_p_idx] @ y_p[Km_p_idx])  + crev[i]\n",
    "                                     - cp.multiply(np.ones(1), -S.T[i, S_s_idx] @ y_s[Km_s_idx])  - cfwd[i]\n",
    "                                     #-1*np.ones(n_lse_terms - n_term + 1) \n",
    "                                   ]\n",
    "                                 )\n",
    "                       )  # remove +1 here, could also have cfwd outside objec. \n",
    "        \n",
    "    # keep saturation term the same, switch around fwd and rev terms. flip all signs with S matrix since it's signed. \n",
    "    if sign[i] == -1:\n",
    "        LSE_expr.append(cp.hstack( [ lvE[i] + (C_alpha @ y_f)[d_alpha == i] - cp.multiply(np.ones(n_term_s), S.T[i, S_p_idx] @ y_p[Km_p_idx]) - crev[i],  \n",
    "                                     lvE[i] + (C_beta @ y_r)[d_beta == i] - cp.multiply(np.ones(n_term_p), S.T[i, S_p_idx] @ y_p[Km_p_idx]) - crev[i],\n",
    "                                     lvE[i] + 0 - cp.multiply(np.ones(1), S.T[i, S_p_idx] @ y_p[Km_p_idx]) - crev[i],\n",
    "                                     cp.multiply(np.ones(1), - S.T[i, S_s_idx] @ y_s[Km_s_idx])  + cfwd[i]\n",
    "                                     - cp.multiply(np.ones(1), S.T[i, S_p_idx] @ y_p[Km_p_idx]) - crev[i],\n",
    "                                     #-1*np.ones(n_lse_terms - n_term + 1) \n",
    "                                   ]\n",
    "                                 )\n",
    "                       )\n",
    "    \n",
    "#LSE_expr = cp.vstack(LSE_expr)\n",
    "LSE_expr"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "46556e00-d226-4552-bdf2-036d770cd0e0",
   "metadata": {},
   "source": [
    "l = 0.0000001\n",
    "e = 0.00001\n",
    "f = 0.0000001\n",
    "reg =  cp.sum(cp.hstack([cfwd, crev, c])) + cp.sum(cp.hstack([-Km_s, -Km_p]))# regularization\n",
    "reg2 = cp.norm1(cp.hstack([cfwd, crev, c])) + cp.norm1(cp.hstack([-Km_s, -Km_p]))# regularization\n",
    "reg3 = cp.sum(cp.huber(cp.hstack([y_s, y_p]), 1))\n",
    "\n",
    "if n_Km_i:\n",
    "    reg += cp.sum(cp.hstack([-Km_i]))\n",
    "if n_Km_a:\n",
    "    reg += cp.sum(cp.hstack([-Km_a]))\n",
    "#reg3 = cp.norm1(cp.hstack([y_s, y_p])) # take a look at this\n",
    "\n",
    "loss = 0\n",
    "for i in range(n_rxn):\n",
    "    loss += cp.norm2(cp.pos(cp.log_sum_exp(LSE_expr[i])))\n",
    "loss += l * reg \n",
    "loss += e * reg2\n",
    "loss += f * reg3\n",
    "# "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "683d5edf-a9df-49d9-a455-f44f87c87fdc",
   "metadata": {},
   "source": [
    "constr = [cp.hstack([cfwd, crev, c, Km_s, Km_p]) >= -12,\n",
    "          cp.hstack([cfwd, crev, c, Km_s, Km_p]) <= 12,\n",
    "          ]\n",
    "\n",
    "if n_Km_i:\n",
    "    constr.extend([Km_i >= -12, Km_i <= 12])\n",
    "if n_Km_a:\n",
    "    constr.extend([Km_a >= -12, Km_a <= 12])\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "1ce681a9-0abc-41c2-a6a1-c1abae1c1a2b",
   "metadata": {},
   "source": [
    "haldane = []\n",
    "fwd_flux = []\n",
    "equilibrium = []\n",
    "\n",
    "for i, r in enumerate(S.T):\n",
    "    Km_s_idx = np.nonzero(S_s_nz[1, :] == i)\n",
    "    S_s_idx = S_s_nz[0, S_s_nz[1, :] == i] # negate -1 entries\n",
    "    \n",
    "    Km_p_idx = np.nonzero(S_p_nz[1, :] == i)\n",
    "    S_p_idx = S_p_nz[0, S_p_nz[1, :] == i]\n",
    "    \n",
    "    haldane.append(K_eq[i] == cfwd[i] - crev[i] + r[S_p_idx] @ Km_p[Km_p_idx] - (-r[S_s_idx]) @ Km_s[Km_s_idx])  # add minus since s matrix has minus\n",
    "    \n",
    "    if sign[i] == 1:\n",
    "        fwd_flux.append(cfwd[i] + (-r[S_s_idx]) @ y_s[Km_s_idx] - (crev[i] + r[S_p_idx] @ y_p[Km_p_idx])  >= 0)  # add minus since s matrix has minus\n",
    "        # equilibrium.append(r @ c <= K_eq[i])\n",
    "        \n",
    "    if sign[i] == -1:\n",
    "        fwd_flux.append(cfwd[i] + (-r[S_s_idx]) @ y_s[Km_s_idx] - (crev[i] + r[S_p_idx] @ y_p[Km_p_idx])  <= 0)  # add minus since s matrix has minus\n",
    "        # equilibrium.append(r @ c >= K_eq[i])\n",
    "        \n",
    "        \n",
    "constr.extend(haldane)\n",
    "constr.extend(fwd_flux)\n",
    "# constr.extend(equilibrium)\n",
    "constr.extend([cp.multiply(S.T @ c, sign)  <= cp.multiply(K_eq, sign)])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "7165f3bc-4f92-4ecd-9fa5-72df801f2cfb",
   "metadata": {},
   "source": [
    "p = cp.Problem(cp.Minimize(loss), constr)\n",
    "p.solve(verbose=False, solver=cp.ECOS)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "a23ff96b-063d-4f2d-8704-824aa46b6947",
   "metadata": {},
   "source": [
    "print('Substrate Km:', [f'{val:.3f}' for val in np.exp(Km_s.value)])\n",
    "print('Product Km:', [f'{val:.3f}' for val in np.exp(Km_p.value)])\n",
    "print('Fwd kcat:', [f'{val:.3f}' for val in np.exp(cfwd.value)])\n",
    "print('Rev kcat:', [f'{val:.3f}' for val in np.exp(crev.value)])\n",
    "print('Concentrations:', [f'{val:.3f}' for val in np.exp(c.value)])\n",
    "\n",
    "if n_Km_i:\n",
    "    print('Inhibition Km:', [f'{val:.3f}' for val in np.exp(Km_i.value)])\n",
    "if n_Km_a:\n",
    "    print('Activation Km:', [f'{val:.3f}' for val in np.exp(Km_a.value)])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "6b2045c6-2811-44a6-866d-1669a8cbe536",
   "metadata": {},
   "source": [
    "# Substrate Km: ['1.000', '1.000', '1.000', '1.000', '1.000', '1.000', '1.000']\n",
    "# Product Km: ['1.000', '1.254', '1.254', '1.254', '1.301', '1.000', '1.000']\n",
    "# Fwd kcat: ['2335.276', '84.350', '86.378', '28.344']\n",
    "# Rev kcat: ['0.946', '0.015', '7.846', '2.939']\n",
    "# Concentrations: ['1.000', '1.000', '1.000', '1.000', '1.000', '1.000', '1.251', '2.221', '2.221']\n",
    "# Activation Km: ['0.562', '0.583']\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "d22a7c8e-d9de-4a4b-91ff-878b49c487ee",
   "metadata": {},
   "source": [
    "## Check equilibrium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4f70bd67-fc44-4a91-8610-394365c463a9",
   "metadata": {},
   "source": [
    "np.multiply(S.T @ c.value, sign)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1e450d61-0061-4ce9-ac57-799a7f0b7db0",
   "metadata": {},
   "source": [
    "np.multiply(K_eq, sign)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "cb9f9c30-3c2c-402a-a0bc-c77ba84b4d61",
   "metadata": {},
   "source": [
    "## Check flux reconstruction with inhibition/activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5e054d57-710b-4cf5-b54d-4a74deadbcea",
   "metadata": {},
   "source": [
    "sat_expr = []\n",
    "fwd_sat = np.zeros(n_rxn)\n",
    "back_sat = np.zeros(n_rxn)\n",
    "sat = np.zeros(n_rxn)\n",
    "\n",
    "for i in range(n_rxn):\n",
    "    # sum terms are separate in logsumexp. one per saturation term (row in C_alpha, C_beta)\n",
    "    n_term_s = np.sum(d_alpha == i) \n",
    "    n_term_p = np.sum(d_beta == i)\n",
    "    n_term = n_term_s + n_term_p\n",
    "    \n",
    "    \n",
    "    Km_s_idx = np.nonzero(S_s_nz[1, :] == i)\n",
    "    S_s_idx = S_s_nz[0, S_s_nz[1, :] == i] # negate -1 entries\n",
    "    \n",
    "    Km_p_idx = np.nonzero(S_p_nz[1, :] == i)\n",
    "    S_p_idx = S_p_nz[0, S_p_nz[1, :] == i]\n",
    "    \n",
    "    #S_s_idx = S_s_nz[0, S_s_nz[1, :] == i]\n",
    "    \n",
    "    sat_expr.append(           [ (C_alpha @ y_f.value)[d_alpha == i] ,  \n",
    "                                 (C_beta @ y_r.value)[d_beta == i],\n",
    "                                 0,\n",
    "                                 #-1*np.ones(n_lse_terms - n_term + 1) \n",
    "                               ]\n",
    "                   )\n",
    "    fwd_sat[i] = (np.exp(-S.T[i, S_s_idx] @ y_s.value[Km_s_idx])) # + cfwd.value[i]\n",
    "    back_sat[i] = (np.exp(S.T[i, S_p_idx] @ y_p.value[Km_p_idx])) # + cfwd.value[i]\n",
    "    \n",
    "    \n",
    "\n",
    "for i, rxn in enumerate(sat_expr):\n",
    "    s = 0\n",
    "    \n",
    "    for term in rxn:\n",
    "        s += np.sum(np.exp(term))\n",
    "        \n",
    "    sat[i] = (s)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "209b4849-e84e-4d01-b174-6524e485609c",
   "metadata": {},
   "source": [
    "np.exp(cfwd.value) * fwd_sat/sat"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "44cdde16-9cf3-4774-8eea-616bf5f9a367",
   "metadata": {},
   "source": [
    "- np.exp(crev.value) * back_sat/sat"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a5219ac6-8feb-46c9-add8-215a0e6dec4f",
   "metadata": {},
   "source": [
    "np.exp(cfwd.value) * fwd_sat/sat - np.exp(crev.value) * back_sat/sat"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "971b3404-a8d4-4beb-9912-641efbac7e5b",
   "metadata": {},
   "source": [
    "Km_a.value"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "696c8e18-e95c-4e4c-bb22-d5594e619c4a",
   "metadata": {},
   "source": [
    "Both enzymes have a much higher concentration than K_a, e.g. both are activated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "150ff29f-9c11-4a20-a2e1-c27f18ccbd31",
   "metadata": {},
   "source": [
    "np.exp(-y_a.value)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "11b80a4d-f366-437d-9a36-4a82ac4f3936",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c87faa95-2adf-4141-801c-8296d5cf3783",
   "metadata": {},
   "source": [
    "# Adding flux set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c40d66ec-d3ac-4858-bef4-fbd8e5c85451",
   "metadata": {},
   "source": [
    "Sd = pd.DataFrame(stoich_dict, dtype=np.int8).fillna(0).astype(np.int8)\n",
    "# Sd = Sd.iloc[0:7, 0:2]\n",
    "\n",
    "n_met = len(Sd.index)\n",
    "n_rxn = len(Sd.columns)\n",
    "\n",
    "Sd"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "40d1893b-dd37-4210-b055-68b9d1d2c737",
   "metadata": {},
   "source": [
    "K_eq = np.log(keq)\n",
    "K_eq_mod = K_eq[:, np.newaxis].T\n",
    "vE = np.array([[90, 70, -30, 50], [100, 100, 30, 50], [110, 60, 75, 50]])\n",
    "\n",
    "n_flux_set = vE.shape[0]\n",
    "\n",
    "# K_eq[vE < 0] = 1/K_eq[vE < 0] \n",
    "\n",
    "lvE = np.log(np.abs(vE))\n",
    "pd.DataFrame(np.concatenate([K_eq_mod, vE, np.sign(vE, dtype=np.int8)]), columns=Sd.columns, \n",
    "             index=[\"$K_{eq}$\", \"$v_1$\", \"$v_2$\", \"$v_3$\", \"sign 1\", \"sign 2\", \"sign 3\"])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "24e1a2b1-932e-4de3-92eb-deafc727c1db",
   "metadata": {},
   "source": [
    "# set up variables\n",
    "\n",
    "S = np.array(Sd)\n",
    "# S = np.multiply(S, vE/np.abs(vE)).astype(np.int8) # flips signs on reverse reactions, not needed\n",
    "# S[S == -0] = 0\n",
    "S_s = -np.copy(S) # reverse neg sign\n",
    "S_p = np.copy(S) \n",
    "S_s[S > 0] = 0 # zeros products\n",
    "S_p[S < 0] = 0 # zeros substrates\n",
    "S_i = np.copy(np.array(Sr) == -1) # reaction direction does not matter\n",
    "S_a = np.copy(np.array(Sr) == 1)\n",
    "\n",
    "\n",
    "S_s_nz = np.array(S_s.nonzero())\n",
    "S_p_nz = np.array(S_p.nonzero())\n",
    "S_i_nz = np.array(S_i.nonzero())\n",
    "S_a_nz = np.array(S_a.nonzero())\n",
    "\n",
    "# TODO Refactor all the below lines as one liners \n",
    "# first coordinate, e.g. metabolites w nonzero substrate/product coeff across all reactions. also works as substrate indices. \n",
    "met_s_nz = S_s_nz[0, :]\n",
    "met_p_nz = S_p_nz[0, :]\n",
    "met_i_nz = S_i_nz[0, :]\n",
    "met_a_nz = S_a_nz[0, :]\n",
    "\n",
    "# second coordinate, e.g. reactions indices for those concentrations. works to index substrates as well. \n",
    "rxn_s_nz = S_s_nz[1, :]   \n",
    "rxn_p_nz = S_p_nz[1, :]\n",
    "rxn_i_nz = S_i_nz[1, :]\n",
    "rxn_a_nz = S_a_nz[1, :]\n",
    "\n",
    "# one dim is always 2\n",
    "n_Km_s = np.max(met_s_nz.shape) \n",
    "n_Km_p = np.max(met_p_nz.shape)\n",
    "n_Km_i = np.max(met_i_nz.shape) \n",
    "n_Km_a = np.max(met_a_nz.shape)\n",
    "\n",
    "c = cp.Variable([n_met, n_flux_set])\n",
    "Km_s = cp.Variable(n_Km_s)\n",
    "Km_p = cp.Variable(n_Km_p)\n",
    "Km_i = cp.Variable(n_Km_i) if n_Km_i else None\n",
    "Km_a = cp.Variable(n_Km_a) if n_Km_a else None\n",
    "\n",
    "cfwd = cp.Variable(n_rxn)\n",
    "crev = cp.Variable(n_rxn)\n",
    "\n",
    "# define y vecs\n",
    "y_s_t = []\n",
    "y_p_t = []\n",
    "y_i_t = []\n",
    "y_a_t = []\n",
    "\n",
    "# define Km positions by nonzero S matrix concentrations. Activation is reverse val of inhibition.\n",
    "# TODO Add molecularity here.\n",
    "for i in range(n_flux_set):\n",
    "    y_s_t.append(c[met_s_nz, i] - Km_s)\n",
    "    y_p_t.append(c[met_p_nz, i] - Km_p)\n",
    "    y_i_t.append(c[met_i_nz, i] - Km_i if n_Km_i else None)\n",
    "    y_a_t.append(-(c[met_a_nz, i] - Km_a) if n_Km_a else None)\n",
    "\n",
    "y_s = cp.vstack(y_s_t)\n",
    "y_p = cp.vstack(y_p_t)\n",
    "y_i = cp.vstack(y_i_t)\n",
    "y_a = cp.vstack(y_a_t)\n",
    "    \n",
    "# saturation stacks\n",
    "y_f_vec = [y_s]\n",
    "y_r_vec = [y_p]\n",
    "if n_Km_i:\n",
    "    y_f_vec.append(y_i)\n",
    "    y_r_vec.append(y_i)\n",
    "if n_Km_a:\n",
    "    y_f_vec.append(y_a)\n",
    "    y_r_vec.append(y_a)    \n",
    "\n",
    "y_f = cp.hstack(y_f_vec)\n",
    "y_r = cp.hstack(y_r_vec)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b1b29b6a-4722-445c-adcf-0af90268d044",
   "metadata": {},
   "source": [
    "# number of saturation terms for sub, prod\n",
    "S_s_comb = np.concatenate((S_s, S_i, S_a), axis=0)\n",
    "S_p_comb = np.concatenate((S_p, S_i, S_a), axis=0)\n",
    "n_alpha = np.sum(np.power(2, S_s_comb.sum(axis=0)) - 1)\n",
    "n_beta = np.sum(np.power(2, S_p_comb.sum(axis=0)) - 1)\n",
    "\n",
    "# saturation matrix setup, first sub, then inhib, then act. \n",
    "C_alpha = np.zeros([n_alpha, len(met_s_nz) + len(met_i_nz) + len(met_a_nz)])\n",
    "C_beta = np.zeros([n_beta, len(met_p_nz) + len(met_i_nz) + len(met_a_nz)])\n",
    "\n",
    "# to separate different reactions saturation terms to their individual reaction equations. \n",
    "d_alpha = np.zeros(n_alpha, dtype=np.int8)\n",
    "d_beta = np.zeros(n_beta, dtype=np.int8)\n",
    "\n",
    "\n",
    "idx = 0\n",
    "\n",
    "for i in range(n_rxn):\n",
    "    \n",
    "    # pick one reaction at a time (get substrate indicies)\n",
    "    #idx_cur_rxn = rxn_s_nz == i\n",
    "    # TODO This does not properly multiply by molecularity. Alternatively, generate C_alpha and\n",
    "    # TODO beta without molecularity (first ==1) and then multiply by molecularity in the end.\n",
    "    idx_cur_rxn = np.concatenate((rxn_s_nz == i, rxn_i_nz == i, rxn_a_nz == i))\n",
    "    \n",
    "    # generates all binary permutations minus the first one since that would result in -1\n",
    "    sat_perm = np.array(list(itertools.product([0, 1], repeat=sum(idx_cur_rxn))))\n",
    "    sat_perm = sat_perm[1:, :]\n",
    "    \n",
    "    r, _ = sat_perm.shape\n",
    "    \n",
    "    # replace zeros with saturation matrix\n",
    "    C_alpha[idx:(idx+r), idx_cur_rxn] = sat_perm\n",
    "    d_alpha[idx:(idx+r)] = i\n",
    "        \n",
    "    idx += r # add row # \n",
    "\n",
    "idx = 0\n",
    "    \n",
    "for i in range(n_rxn):\n",
    "    idx_cur_rxn = np.concatenate((rxn_p_nz == i, rxn_i_nz == i, rxn_a_nz == i))\n",
    "    \n",
    "    sat_perm = np.array(list(itertools.product([0, 1], repeat=sum(idx_cur_rxn))))\n",
    "    sat_perm = sat_perm[1:, :]\n",
    "    \n",
    "    r, _ = sat_perm.shape\n",
    "    \n",
    "    C_beta[idx:(idx+r), idx_cur_rxn] = sat_perm\n",
    "    d_beta[idx:(idx+r)] = i\n",
    "        \n",
    "    idx += r # add row # "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2d2ec614-798c-44c8-be85-413bf53d78bb",
   "metadata": {},
   "source": [
    "n_lse_terms = np.max(np.power(2, S_s.sum(axis=0)) +  np.power(2, S_p.sum(axis=0)) - 2)\n",
    "LSE_expr = []\n",
    "denom_expr = []\n",
    "\n",
    "sign = np.sign(vE)\n",
    "lvE = np.log(sign * vE)\n",
    "\n",
    "for j in range(n_flux_set):\n",
    "    for i in range(n_rxn):\n",
    "        # sum terms are separate in logsumexp. one per saturation term (row in C_alpha, C_beta)\n",
    "\n",
    "        n_term_s = np.sum(d_alpha == i) \n",
    "        n_term_p = np.sum(d_beta == i)\n",
    "        n_term = n_term_s + n_term_p\n",
    "\n",
    "        Km_s_idx = np.nonzero(S_s_nz[1, :] == i)\n",
    "        S_s_idx = S_s_nz[0, S_s_nz[1, :] == i] # negate -1 entries\n",
    "\n",
    "        Km_p_idx = np.nonzero(S_p_nz[1, :] == i)\n",
    "        S_p_idx = S_p_nz[0, S_p_nz[1, :] == i]\n",
    "        \n",
    "        if sign[j, i] == 1:\n",
    "            LSE_expr.append(cp.hstack( [ \n",
    "                                         lvE[j, i] + (C_alpha @ cp.vec(y_f[j, :]))[d_alpha == i] \n",
    "                                            - cp.multiply(np.ones(n_term_s), - S.T[i, S_s_idx] @ cp.vec(y_s[j, Km_s_idx])) - cfwd[i],  \n",
    "                                         lvE[j, i] + (C_beta @ cp.vec(y_r[j, :]))[d_beta == i] \n",
    "                                            - cp.multiply(np.ones(n_term_p), - S.T[i, S_s_idx] @ cp.vec(y_s[j, Km_s_idx])) - cfwd[i],\n",
    "                \n",
    "                                         lvE[j, i] + 0 - cp.multiply(np.ones(1), -S.T[i, S_s_idx] @ cp.vec(y_s[j, Km_s_idx]))  - cfwd[i],\n",
    "                \n",
    "                                         cp.multiply(np.ones(1), S.T[i, S_p_idx] @ cp.vec(y_p[j, Km_p_idx]))  + crev[i]\n",
    "                                            - cp.multiply(np.ones(1), -S.T[i, S_s_idx] @ cp.vec(y_s[j, Km_s_idx]))  - cfwd[i],\n",
    "                \n",
    "                                       ]\n",
    "                                     )\n",
    "                           )  # remove +1 here, could also have cfwd outside objec.\n",
    "            \n",
    "            denom_expr.append(cp.multiply(np.ones(1), -S.T[i, S_s_idx] @ cp.vec(y_s[j, Km_s_idx])) + cfwd[i],)\n",
    "            \n",
    "\n",
    "        # keep saturation term the same, switch around fwd and rev terms. flip all signs with S matrix since it's signed. \n",
    "        if sign[j, i] == -1:\n",
    "            LSE_expr.append(cp.hstack( [ lvE[j, i] + (C_alpha @ cp.vec(y_f[j, :]))[d_alpha == i] \n",
    "                                            - cp.multiply(np.ones(n_term_s), S.T[i, S_p_idx] @ cp.vec(y_p[j, Km_p_idx])) - crev[i],  \n",
    "                                        \n",
    "                                         lvE[j, i] + (C_beta @ cp.vec(y_r[j, :]))[d_beta == i] \n",
    "                                            - cp.multiply(np.ones(n_term_p), S.T[i, S_p_idx] @ cp.vec(y_p[j, Km_p_idx])) - crev[i],\n",
    "                                        \n",
    "                                         lvE[j, i] + 0 - cp.multiply(np.ones(1), S.T[i, S_p_idx] @ cp.vec(y_p[j, Km_p_idx])) - crev[i],\n",
    "                                        \n",
    "                                         cp.multiply(np.ones(1), - S.T[i, S_s_idx] @ cp.vec(y_s[j, Km_s_idx]))  + cfwd[i]\n",
    "                                            - cp.multiply(np.ones(1), S.T[i, S_p_idx] @ cp.vec(y_p[j, Km_p_idx])) - crev[i],\n",
    "                                        \n",
    "                                       ]\n",
    "                                     )\n",
    "                           )\n",
    "            \n",
    "            denom_expr.append(cp.multiply(np.ones(1), S.T[i, S_p_idx] @ cp.vec(y_p[j, Km_p_idx])) + crev[i])\n",
    "            \n",
    "\n",
    "#LSE_expr = cp.vstack(LSE_expr)\n",
    "LSE_expr"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e7bc83ed-8678-4596-8fa8-d594e941f045",
   "metadata": {},
   "source": [
    "l = 0.001\n",
    "e = 0.001\n",
    "f = 0.000001\n",
    "reg =  cp.sum(cp.hstack([cfwd, crev, cp.vec(c)])) + cp.sum(cp.hstack([-Km_s, -Km_p])) # regularization\n",
    "reg2 = cp.norm1(cp.hstack([cfwd, crev, cp.vec(c)])) + cp.norm1(cp.hstack([-Km_s, -Km_p])) # regularization\n",
    "reg3 = cp.sum(cp.huber(cp.hstack([y_s, y_p]), 1)) # issue with matrix\n",
    "\n",
    "if n_Km_i:\n",
    "    reg += cp.sum(cp.hstack([-Km_i]))\n",
    "if n_Km_a:\n",
    "    reg += cp.sum(cp.hstack([-Km_a]))\n",
    "#reg3 = cp.norm1(cp.hstack([y_s, y_p])) # take a look at this\n",
    "\n",
    "loss = 0\n",
    "for i in range(len(LSE_expr)):\n",
    "    loss += cp.norm1(cp.pos(cp.log_sum_exp(LSE_expr[i])))\n",
    "for i in range(len(denom_expr)):\n",
    "    loss += 0.01 * denom_expr[i]\n",
    "loss += l * reg \n",
    "loss += e * reg2\n",
    "loss += f * reg3\n",
    "# "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7772e167-8115-4513-94c7-dce58e9392bd",
   "metadata": {},
   "source": [
    "constr = [cp.hstack([cfwd, crev, cp.vec(c), Km_s, Km_p]) >= -12,\n",
    "          cp.hstack([cfwd, crev, cp.vec(c), Km_s, Km_p]) <= 12,\n",
    "          ]\n",
    "\n",
    "if n_Km_i:\n",
    "    constr.extend([Km_i >= -12, Km_i <= 12])\n",
    "if n_Km_a:\n",
    "    constr.extend([Km_a >= -12, Km_a <= 12])\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4f417489-a4e9-496f-8967-297b575685a8",
   "metadata": {},
   "source": [
    "constr.extend([Km_a[0] == -1])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "05a47e3f-3555-43ad-89e4-939b4b27b149",
   "metadata": {},
   "source": [
    "haldane = []\n",
    "fwd_flux = []\n",
    "\n",
    "for i, r in enumerate(S.T):\n",
    "    Km_s_idx = np.nonzero(S_s_nz[1, :] == i)\n",
    "    S_s_idx = S_s_nz[0, S_s_nz[1, :] == i] # negate -1 entries\n",
    "\n",
    "    Km_p_idx = np.nonzero(S_p_nz[1, :] == i)\n",
    "    S_p_idx = S_p_nz[0, S_p_nz[1, :] == i]\n",
    "\n",
    "    haldane.append(K_eq[i] == cfwd[i] - crev[i] + r[S_p_idx] @ Km_p[Km_p_idx] - (-r[S_s_idx]) @ Km_s[Km_s_idx])\n",
    "\n",
    "for j in range(n_flux_set):\n",
    "    for i, r in enumerate(S.T):\n",
    "        Km_s_idx = np.nonzero(S_s_nz[1, :] == i)\n",
    "        S_s_idx = S_s_nz[0, S_s_nz[1, :] == i] # negate -1 entries\n",
    "\n",
    "        Km_p_idx = np.nonzero(S_p_nz[1, :] == i)\n",
    "        S_p_idx = S_p_nz[0, S_p_nz[1, :] == i]\n",
    "\n",
    "        if sign[j, i] == 1:\n",
    "            fwd_flux.append(cfwd[i] + (-r[S_s_idx]) @ cp.vec(y_s[j, Km_s_idx]) - (crev[i] + r[S_p_idx] @ cp.vec(y_p[j, Km_p_idx]))  >= 0)  # add minus since s matrix has minus\n",
    "            # equilibrium.append(r @ c <= K_eq[i])\n",
    "\n",
    "        if sign[j, i] == -1:\n",
    "            fwd_flux.append(cfwd[i] + (-r[S_s_idx]) @ cp.vec(y_s[j, Km_s_idx]) - (crev[i] + r[S_p_idx] @ cp.vec(y_p[j, Km_p_idx]))  <= 0)  # add minus since s matrix has minus\n",
    "            # equilibrium.append(r @ c >= K_eq[i])\n",
    "        \n",
    "        \n",
    "    constr.extend([cp.multiply(S.T @ cp.vec(c[:, j]), sign[j, :])  <= cp.multiply(K_eq, sign[j, :])])\n",
    "        \n",
    "constr.extend(haldane)\n",
    "constr.extend(fwd_flux)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ce648a93-611d-4de9-b9c2-e705248c2477",
   "metadata": {},
   "source": [
    "p = cp.Problem(cp.Minimize(loss), constr)\n",
    "p.solve(verbose=False, solver=cp.ECOS)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d868f215-1b91-47a9-aebc-de86d93a7b2b",
   "metadata": {},
   "source": [
    "print('Substrate Km:', [f'{val:.3f}' for val in np.exp(Km_s.value)])\n",
    "print('Product Km:', [f'{val:.3f}' for val in np.exp(Km_p.value)])\n",
    "print('Fwd kcat:', [f'{val:.3f}' for val in np.exp(cfwd.value)])\n",
    "print('Rev kcat:', [f'{val:.3f}' for val in np.exp(crev.value)])\n",
    "\n",
    "concs = np.exp(c.value).T\n",
    "for row in concs:\n",
    "    print('Concentration:', [f'{val:.4f}' for val in row])\n",
    "\n",
    "if n_Km_i:\n",
    "    print('Inhibition Km:', [f'{val:.3f}' for val in np.exp(Km_i.value)])\n",
    "if n_Km_a:\n",
    "    print('Activation Km:', [f'{val:.3f}' for val in np.exp(Km_a.value)])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c2d37cd8-642c-4a89-9774-35dbc82fa1bd",
   "metadata": {},
   "source": [
    "for v in LSE_expr:\n",
    "    #print(v.value)\n",
    "    print(logsumexp(v.value))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "f71f2d28-e630-448a-91c1-abd47a28543e",
   "metadata": {},
   "source": [
    "Perfect? Wow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba22b98-c325-4548-a2ff-5d62225ad78f",
   "metadata": {},
   "source": [
    "# Check flux reconstruction with inhibition/activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "134d5038-95e8-4f0f-9b63-59c831cfe969",
   "metadata": {},
   "source": [
    "reconstructed_vE = np.zeros(vE.shape)\n",
    "\n",
    "for j in range(n_flux_set):\n",
    "    sat_expr = []\n",
    "    fwd_sat = np.zeros(n_rxn)\n",
    "    back_sat = np.zeros(n_rxn)\n",
    "    sat = np.zeros(n_rxn)\n",
    "\n",
    "    for i in range(n_rxn):\n",
    "        # sum terms are separate in logsumexp. one per saturation term (row in C_alpha, C_beta)\n",
    "        n_term_s = np.sum(d_alpha == i) \n",
    "        n_term_p = np.sum(d_beta == i)\n",
    "        n_term = n_term_s + n_term_p\n",
    "\n",
    "\n",
    "        Km_s_idx = np.nonzero(S_s_nz[1, :] == i)\n",
    "        S_s_idx = S_s_nz[0, S_s_nz[1, :] == i] # negate -1 entries\n",
    "\n",
    "        Km_p_idx = np.nonzero(S_p_nz[1, :] == i)\n",
    "        S_p_idx = S_p_nz[0, S_p_nz[1, :] == i]\n",
    "\n",
    "        #S_s_idx = S_s_nz[0, S_s_nz[1, :] == i]\n",
    "\n",
    "        sat_expr.append(           [ (C_alpha @ y_f.value[j, :].flatten())[d_alpha == i] ,  \n",
    "                                     (C_beta @ y_r.value[j, :].flatten())[d_beta == i],\n",
    "                                     0,\n",
    "                                     #-1*np.ones(n_lse_terms - n_term + 1) \n",
    "                                   ]\n",
    "                       )\n",
    "        fwd_sat[i] = (np.exp(-S.T[i, S_s_idx] @ y_s.value[j, Km_s_idx].flatten())) # + cfwd.value[i]\n",
    "        back_sat[i] = (np.exp(S.T[i, S_p_idx] @ y_p.value[j, Km_p_idx].flatten())) # + cfwd.value[i]\n",
    "\n",
    "\n",
    "\n",
    "    for i, rxn in enumerate(sat_expr):\n",
    "        s = 0\n",
    "\n",
    "        for term in rxn:\n",
    "            s += np.sum(np.exp(term))\n",
    "\n",
    "        sat[i] = (s)\n",
    "\n",
    "    reconstr = np.exp(cfwd.value) * fwd_sat/sat - np.exp(crev.value) * back_sat/sat\n",
    "    print(reconstr)\n",
    "    reconstructed_vE[j, :] = reconstr"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "df_vE = pd.DataFrame(vE, columns=Sd.columns, index=[\"Flux set 1\", \"Flux set 2\", \"Flux set 3\"]).melt(ignore_index=False).reset_index(drop=False)\n",
    "df_vE[\"kind\"] = \"Actual flux\"\n",
    "df_recon = pd.DataFrame(reconstructed_vE, columns=Sd.columns, index=[\"Flux set 1\", \"Flux set 2\", \"Flux set 3\"]).melt(ignore_index=False).reset_index(drop=False)\n",
    "df_recon[\"kind\"] = \"Reconstructed flux\"\n",
    "\n",
    "df_reconstr_comp = pd.concat([df_vE, df_recon]).reset_index(drop=True)\n",
    "df_reconstr_comp"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b56bb616b89a32a3",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "sns.catplot(x=\"index\", y=\"value\", hue=\"kind\", col=\"variable\", kind=\"bar\", data=df_reconstr_comp, height=5, aspect=1, col_wrap=2)\n",
    "plt.savefig(\"flux_set_comparison.svg\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5fb07e42b02c818d",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "374a05f5-9031-4711-a578-e9d2f85e99d9",
   "metadata": {},
   "source": [
    "# Add molecularity factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "Sd = pd.DataFrame(stoich_dict, dtype=np.int8).fillna(0).astype(np.int8)\n",
    "# Sd = Sd.iloc[0:7, 0:2]\n",
    "\n",
    "n_met = len(Sd.index)\n",
    "n_rxn = len(Sd.columns)\n",
    "\n",
    "Sd[\"6PFRUCTPHOS-RXN\"] = Sd[\"6PFRUCTPHOS-RXN\"] * 2\n",
    "Sd"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "efbdc3f1448bfe96",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "K_eq = np.log(keq)\n",
    "K_eq_mod = K_eq[:, np.newaxis].T\n",
    "vE = np.array([[90, 70, -30, 50], [100, 100, 30, 50], [110, 60, 75, 50]])\n",
    "vE[:, 0] = vE[:, 0] / 2\n",
    "\n",
    "n_flux_set = vE.shape[0]\n",
    "\n",
    "# K_eq[vE < 0] = 1/K_eq[vE < 0]\n",
    "\n",
    "lvE = np.log(np.abs(vE))\n",
    "pd.DataFrame(np.concatenate([K_eq_mod, vE, np.sign(vE, dtype=np.int8)]), columns=Sd.columns,\n",
    "             index=[\"$K_{eq}$\", \"$v_1$\", \"$v_2$\", \"$v_3$\", \"sign 1\", \"sign 2\", \"sign 3\"])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50c69e61e75d9744",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "# set up variables\n",
    "\n",
    "S_mol = np.array(Sd)\n",
    "S = np.sign(S_mol) #\n",
    "S_s = -np.copy(S) # reverse neg sign\n",
    "S_p = np.copy(S)\n",
    "S_s[S > 0] = 0 # zeros products\n",
    "S_p[S < 0] = 0 # zeros substrates\n",
    "S_i = np.copy(np.array(Sr) == -1) # reaction direction does not matter\n",
    "S_a = np.copy(np.array(Sr) == 1)\n",
    "\n",
    "\n",
    "S_s_nz = np.array(S_s.nonzero())\n",
    "S_p_nz = np.array(S_p.nonzero())\n",
    "S_i_nz = np.array(S_i.nonzero())\n",
    "S_a_nz = np.array(S_a.nonzero())\n",
    "S_s_mol = np.abs(S_mol)[S_s.nonzero()]\n",
    "S_p_mol = np.abs(S_mol)[S_p.nonzero()]\n",
    "\n",
    "# TODO Refactor all the below lines as one liners\n",
    "# first coordinate, e.g. metabolites w nonzero substrate/product coeff across all reactions. also works as substrate indices.\n",
    "met_s_nz = S_s_nz[0, :]\n",
    "met_p_nz = S_p_nz[0, :]\n",
    "met_i_nz = S_i_nz[0, :]\n",
    "met_a_nz = S_a_nz[0, :]\n",
    "\n",
    "# second coordinate, e.g. reactions indices for those concentrations. works to index substrates as well.\n",
    "rxn_s_nz = S_s_nz[1, :]\n",
    "rxn_p_nz = S_p_nz[1, :]\n",
    "rxn_i_nz = S_i_nz[1, :]\n",
    "rxn_a_nz = S_a_nz[1, :]\n",
    "\n",
    "# one dim is always 2\n",
    "n_Km_s = np.max(met_s_nz.shape)\n",
    "n_Km_p = np.max(met_p_nz.shape)\n",
    "n_Km_i = np.max(met_i_nz.shape)\n",
    "n_Km_a = np.max(met_a_nz.shape)\n",
    "\n",
    "c = cp.Variable([n_met, n_flux_set])\n",
    "Km_s = cp.Variable(n_Km_s)\n",
    "Km_p = cp.Variable(n_Km_p)\n",
    "Km_i = cp.Variable(n_Km_i) if n_Km_i else None\n",
    "Km_a = cp.Variable(n_Km_a) if n_Km_a else None\n",
    "\n",
    "cfwd = cp.Variable(n_rxn)\n",
    "crev = cp.Variable(n_rxn)\n",
    "\n",
    "# define y vecs\n",
    "y_s_t = []\n",
    "y_p_t = []\n",
    "y_i_t = []\n",
    "y_a_t = []\n",
    "\n",
    "# define Km positions by nonzero S matrix concentrations. Activation is reverse val of inhibition.\n",
    "# TODO Add molecularity here.\n",
    "for i in range(n_flux_set):\n",
    "    y_s_t.append(cp.multiply(S_s_mol, c[met_s_nz, i] - Km_s))\n",
    "    y_p_t.append(cp.multiply(S_p_mol, c[met_p_nz, i] - Km_p))\n",
    "    y_i_t.append(c[met_i_nz, i] - Km_i if n_Km_i else None)\n",
    "    y_a_t.append(-(c[met_a_nz, i] - Km_a) if n_Km_a else None)\n",
    "\n",
    "y_s = cp.vstack(y_s_t)\n",
    "y_p = cp.vstack(y_p_t)\n",
    "y_i = cp.vstack(y_i_t)\n",
    "y_a = cp.vstack(y_a_t)\n",
    "\n",
    "# saturation stacks\n",
    "y_f_vec = [y_s]\n",
    "y_r_vec = [y_p]\n",
    "if n_Km_i:\n",
    "    y_f_vec.append(y_i)\n",
    "    y_r_vec.append(y_i)\n",
    "if n_Km_a:\n",
    "    y_f_vec.append(y_a)\n",
    "    y_r_vec.append(y_a)\n",
    "\n",
    "y_f = cp.hstack(y_f_vec)\n",
    "y_r = cp.hstack(y_r_vec)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "20b49b318b0d97be",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "# number of saturation terms for sub, prod\n",
    "S_s_comb = np.concatenate((S_s, S_i, S_a), axis=0)\n",
    "S_p_comb = np.concatenate((S_p, S_i, S_a), axis=0)\n",
    "n_alpha = np.sum(np.power(2, np.sign(S_s_comb).sum(axis=0)) - 1)\n",
    "n_beta = np.sum(np.power(2, np.sign(S_p_comb).sum(axis=0)) - 1)\n",
    "\n",
    "# saturation matrix setup, first sub, then inhib, then act.\n",
    "C_alpha = np.zeros([n_alpha, len(met_s_nz) + len(met_i_nz) + len(met_a_nz)])\n",
    "C_beta = np.zeros([n_beta, len(met_p_nz) + len(met_i_nz) + len(met_a_nz)])\n",
    "\n",
    "# to separate different reactions saturation terms to their individual reaction equations.\n",
    "d_alpha = np.zeros(n_alpha, dtype=np.int8)\n",
    "d_beta = np.zeros(n_beta, dtype=np.int8)\n",
    "\n",
    "\n",
    "idx = 0\n",
    "\n",
    "for i in range(n_rxn):\n",
    "\n",
    "    # pick one reaction at a time (get substrate indicies)\n",
    "    #idx_cur_rxn = rxn_s_nz == i\n",
    "    # TODO This does not properly multiply by molecularity. Alternatively, generate C_alpha and\n",
    "    # TODO beta without molecularity (first ==1) and then multiply by molecularity in the end.\n",
    "    idx_cur_rxn = np.concatenate((rxn_s_nz == i, rxn_i_nz == i, rxn_a_nz == i))\n",
    "\n",
    "    # generates all binary permutations minus the first one since that would result in -1\n",
    "    sat_perm = np.array(list(itertools.product([0, 1], repeat=sum(idx_cur_rxn))))\n",
    "    sat_perm = sat_perm[1:, :]\n",
    "\n",
    "    r, _ = sat_perm.shape\n",
    "\n",
    "    # replace zeros with saturation matrix\n",
    "    C_alpha[idx:(idx+r), idx_cur_rxn] = sat_perm\n",
    "    d_alpha[idx:(idx+r)] = i\n",
    "\n",
    "    idx += r # add row #\n",
    "\n",
    "idx = 0\n",
    "\n",
    "for i in range(n_rxn):\n",
    "    idx_cur_rxn = np.concatenate((rxn_p_nz == i, rxn_i_nz == i, rxn_a_nz == i))\n",
    "\n",
    "    sat_perm = np.array(list(itertools.product([0, 1], repeat=sum(idx_cur_rxn))))\n",
    "    sat_perm = sat_perm[1:, :]\n",
    "\n",
    "    r, _ = sat_perm.shape\n",
    "\n",
    "    C_beta[idx:(idx+r), idx_cur_rxn] = sat_perm\n",
    "    d_beta[idx:(idx+r)] = i\n",
    "\n",
    "    idx += r # add row #"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e274a01fc7febc0",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "C_alpha"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "737ef1aac7be1210",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "source": [
    "n_lse_terms = np.max(np.power(2, S_s.sum(axis=0)) +  np.power(2, S_p.sum(axis=0)) - 2)\n",
    "LSE_expr = []\n",
    "denom_expr = []\n",
    "\n",
    "sign = np.sign(vE)\n",
    "lvE = np.log(sign * vE)\n",
    "\n",
    "for j in range(n_flux_set):\n",
    "    for i in range(n_rxn):\n",
    "        # sum terms are separate in logsumexp. one per saturation term (row in C_alpha, C_beta)\n",
    "\n",
    "        n_term_s = np.sum(d_alpha == i)\n",
    "        n_term_p = np.sum(d_beta == i)\n",
    "        n_term = n_term_s + n_term_p\n",
    "\n",
    "        Km_s_idx = np.nonzero(S_s_nz[1, :] == i)\n",
    "        S_s_idx = S_s_nz[0, S_s_nz[1, :] == i] # negate -1 entries\n",
    "\n",
    "        Km_p_idx = np.nonzero(S_p_nz[1, :] == i)\n",
    "        S_p_idx = S_p_nz[0, S_p_nz[1, :] == i]\n",
    "\n",
    "        if sign[j, i] == 1:\n",
    "            LSE_expr.append(cp.hstack( [\n",
    "                                         lvE[j, i] + (C_alpha @ cp.vec(y_f[j, :]))[d_alpha == i]\n",
    "                                            - cp.multiply(np.ones(n_term_s), - S.T[i, S_s_idx] @ cp.vec(y_s[j, Km_s_idx])) - cfwd[i],\n",
    "                                         lvE[j, i] + (C_beta @ cp.vec(y_r[j, :]))[d_beta == i]\n",
    "                                            - cp.multiply(np.ones(n_term_p), - S.T[i, S_s_idx] @ cp.vec(y_s[j, Km_s_idx])) - cfwd[i],\n",
    "\n",
    "                                         lvE[j, i] + 0 - cp.multiply(np.ones(1), -S.T[i, S_s_idx] @ cp.vec(y_s[j, Km_s_idx]))  - cfwd[i],\n",
    "\n",
    "                                         cp.multiply(np.ones(1), S.T[i, S_p_idx] @ cp.vec(y_p[j, Km_p_idx]))  + crev[i]\n",
    "                                            - cp.multiply(np.ones(1), -S.T[i, S_s_idx] @ cp.vec(y_s[j, Km_s_idx]))  - cfwd[i],\n",
    "\n",
    "                                       ]\n",
    "                                     )\n",
    "                           )  # remove +1 here, could also have cfwd outside objec.\n",
    "\n",
    "            denom_expr.append(cp.multiply(np.ones(1), -S.T[i, S_s_idx] @ cp.vec(y_s[j, Km_s_idx])) + cfwd[i],)\n",
    "\n",
    "\n",
    "        # keep saturation term the same, switch around fwd and rev terms. flip all signs with S matrix since it's signed.\n",
    "        if sign[j, i] == -1:\n",
    "            LSE_expr.append(cp.hstack( [ lvE[j, i] + (C_alpha @ cp.vec(y_f[j, :]))[d_alpha == i]\n",
    "                                            - cp.multiply(np.ones(n_term_s), S.T[i, S_p_idx] @ cp.vec(y_p[j, Km_p_idx])) - crev[i],\n",
    "\n",
    "                                         lvE[j, i] + (C_beta @ cp.vec(y_r[j, :]))[d_beta == i]\n",
    "                                            - cp.multiply(np.ones(n_term_p), S.T[i, S_p_idx] @ cp.vec(y_p[j, Km_p_idx])) - crev[i],\n",
    "\n",
    "                                         lvE[j, i] + 0 - cp.multiply(np.ones(1), S.T[i, S_p_idx] @ cp.vec(y_p[j, Km_p_idx])) - crev[i],\n",
    "\n",
    "                                         cp.multiply(np.ones(1), - S.T[i, S_s_idx] @ cp.vec(y_s[j, Km_s_idx]))  + cfwd[i]\n",
    "                                            - cp.multiply(np.ones(1), S.T[i, S_p_idx] @ cp.vec(y_p[j, Km_p_idx])) - crev[i],\n",
    "\n",
    "                                       ]\n",
    "                                     )\n",
    "                           )\n",
    "\n",
    "            denom_expr.append(cp.multiply(np.ones(1), S.T[i, S_p_idx] @ cp.vec(y_p[j, Km_p_idx])) + crev[i])\n",
    "\n",
    "\n",
    "#LSE_expr = cp.vstack(LSE_expr)\n",
    "LSE_expr"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "483d8d816043452d",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "source": [
    "l = 0.001\n",
    "e = 0.001\n",
    "f = 0.000001\n",
    "reg =  cp.sum(cp.hstack([cfwd, crev, cp.vec(c)])) + cp.sum(cp.hstack([-Km_s, -Km_p])) # regularization\n",
    "reg2 = cp.norm1(cp.hstack([cfwd, crev, cp.vec(c)])) + cp.norm1(cp.hstack([-Km_s, -Km_p])) # regularization\n",
    "reg3 = cp.sum(cp.huber(cp.hstack([y_s, y_p]), 1)) # issue with matrix\n",
    "\n",
    "if n_Km_i:\n",
    "    reg += cp.sum(cp.hstack([-Km_i]))\n",
    "if n_Km_a:\n",
    "    reg += cp.sum(cp.hstack([-Km_a]))\n",
    "#reg3 = cp.norm1(cp.hstack([y_s, y_p])) # take a look at this\n",
    "\n",
    "loss = 0\n",
    "for i in range(len(LSE_expr)):\n",
    "    loss += cp.norm1(cp.pos(cp.log_sum_exp(LSE_expr[i])))\n",
    "for i in range(len(denom_expr)):\n",
    "    loss += 0.01 * denom_expr[i]\n",
    "loss += l * reg\n",
    "loss += e * reg2\n",
    "loss += f * reg3\n",
    "#"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60edf5df637bf2e8",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "constr = [cp.hstack([cfwd, crev, cp.vec(c), Km_s, Km_p]) >= -12,\n",
    "          cp.hstack([cfwd, crev, cp.vec(c), Km_s, Km_p]) <= 12,\n",
    "          ]\n",
    "\n",
    "if n_Km_i:\n",
    "    constr.extend([Km_i >= -12, Km_i <= 12])\n",
    "if n_Km_a:\n",
    "    constr.extend([Km_a >= -12, Km_a <= 12])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81c69a77c3dfc68e",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "source": [
    "haldane = []\n",
    "fwd_flux = []\n",
    "\n",
    "for i, r in enumerate(S.T):\n",
    "    Km_s_idx = np.nonzero(S_s_nz[1, :] == i)\n",
    "    S_s_idx = S_s_nz[0, S_s_nz[1, :] == i] # negate -1 entries\n",
    "\n",
    "    Km_p_idx = np.nonzero(S_p_nz[1, :] == i)\n",
    "    S_p_idx = S_p_nz[0, S_p_nz[1, :] == i]\n",
    "\n",
    "    haldane.append(K_eq[i] == cfwd[i] - crev[i] + r[S_p_idx] @ Km_p[Km_p_idx] - (-r[S_s_idx]) @ Km_s[Km_s_idx])\n",
    "\n",
    "for j in range(n_flux_set):\n",
    "    for i, r in enumerate(S.T):\n",
    "        Km_s_idx = np.nonzero(S_s_nz[1, :] == i)\n",
    "        S_s_idx = S_s_nz[0, S_s_nz[1, :] == i] # negate -1 entries\n",
    "\n",
    "        Km_p_idx = np.nonzero(S_p_nz[1, :] == i)\n",
    "        S_p_idx = S_p_nz[0, S_p_nz[1, :] == i]\n",
    "\n",
    "        if sign[j, i] == 1:\n",
    "            fwd_flux.append(cfwd[i] + (-r[S_s_idx]) @ cp.vec(y_s[j, Km_s_idx]) - (crev[i] + r[S_p_idx] @ cp.vec(y_p[j, Km_p_idx]))  >= 0)  # add minus since s matrix has minus\n",
    "\n",
    "        if sign[j, i] == -1:\n",
    "            fwd_flux.append(cfwd[i] + (-r[S_s_idx]) @ cp.vec(y_s[j, Km_s_idx]) - (crev[i] + r[S_p_idx] @ cp.vec(y_p[j, Km_p_idx]))  <= 0)  # add minus since s matrix has minus\n",
    "\n",
    "    constr.extend([cp.multiply(S.T @ cp.vec(c[:, j]), sign[j, :])  <= cp.multiply(K_eq, sign[j, :])])\n",
    "\n",
    "constr.extend(haldane)\n",
    "constr.extend(fwd_flux)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "613c0ef65ea92af0",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "p = cp.Problem(cp.Minimize(loss), constr)\n",
    "p.solve(verbose=True, solver=cp.ECOS)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0f0e9ce2511a054",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "source": [
    "print('Substrate Km:', [f'{val:.3f}' for val in np.exp(Km_s.value)])\n",
    "print('Product Km:', [f'{val:.3f}' for val in np.exp(Km_p.value)])\n",
    "print('Fwd kcat:', [f'{val:.3f}' for val in np.exp(cfwd.value)])\n",
    "print('Rev kcat:', [f'{val:.3f}' for val in np.exp(crev.value)])\n",
    "\n",
    "concs = np.exp(c.value).T\n",
    "for row in concs:\n",
    "    print('Concentration:', [f'{val:.4f}' for val in row])\n",
    "\n",
    "if n_Km_i:\n",
    "    print('Inhibition Km:', [f'{val:.3f}' for val in np.exp(Km_i.value)])\n",
    "if n_Km_a:\n",
    "    print('Activation Km:', [f'{val:.3f}' for val in np.exp(Km_a.value)])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c92860f710c0e494",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "source": [
    "for v in LSE_expr:\n",
    "    #print(v.value)\n",
    "    print(logsumexp(v.value))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dba9fef8f397029b",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Perfect? Wow."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9df1031347e4b91d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Check flux reconstruction with inhibition/activation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf0f66d0823972bb"
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "source": [
    "reconstructed_vE = np.zeros(vE.shape)\n",
    "\n",
    "for j in range(n_flux_set):\n",
    "    sat_expr = []\n",
    "    fwd_sat = np.zeros(n_rxn)\n",
    "    back_sat = np.zeros(n_rxn)\n",
    "    sat = np.zeros(n_rxn)\n",
    "\n",
    "    for i in range(n_rxn):\n",
    "        # sum terms are separate in logsumexp. one per saturation term (row in C_alpha, C_beta)\n",
    "        n_term_s = np.sum(d_alpha == i)\n",
    "        n_term_p = np.sum(d_beta == i)\n",
    "        n_term = n_term_s + n_term_p\n",
    "\n",
    "\n",
    "        Km_s_idx = np.nonzero(S_s_nz[1, :] == i)\n",
    "        S_s_idx = S_s_nz[0, S_s_nz[1, :] == i] # negate -1 entries\n",
    "\n",
    "        Km_p_idx = np.nonzero(S_p_nz[1, :] == i)\n",
    "        S_p_idx = S_p_nz[0, S_p_nz[1, :] == i]\n",
    "\n",
    "        #S_s_idx = S_s_nz[0, S_s_nz[1, :] == i]\n",
    "\n",
    "        sat_expr.append(           [ (C_alpha @ y_f.value[j, :].flatten())[d_alpha == i] ,\n",
    "                                     (C_beta @ y_r.value[j, :].flatten())[d_beta == i],\n",
    "                                     0,\n",
    "                                     #-1*np.ones(n_lse_terms - n_term + 1)\n",
    "                                   ]\n",
    "                       )\n",
    "        fwd_sat[i] = (np.exp(-S.T[i, S_s_idx] @ y_s.value[j, Km_s_idx].flatten())) # + cfwd.value[i]\n",
    "        back_sat[i] = (np.exp(S.T[i, S_p_idx] @ y_p.value[j, Km_p_idx].flatten())) # + cfwd.value[i]\n",
    "\n",
    "\n",
    "\n",
    "    for i, rxn in enumerate(sat_expr):\n",
    "        s = 0\n",
    "\n",
    "        for term in rxn:\n",
    "            s += np.sum(np.exp(term))\n",
    "\n",
    "        sat[i] = (s)\n",
    "\n",
    "    reconstr = np.exp(cfwd.value) * fwd_sat/sat - np.exp(crev.value) * back_sat/sat\n",
    "    print(reconstr)\n",
    "    reconstructed_vE[j, :] = reconstr"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ccb53764e000f8d7",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "source": [
    "df_vE = pd.DataFrame(vE, columns=Sd.columns, index=[\"Flux set 1\", \"Flux set 2\", \"Flux set 3\"]).melt(ignore_index=False).reset_index(drop=False)\n",
    "df_vE[\"kind\"] = \"Actual flux\"\n",
    "df_recon = pd.DataFrame(reconstructed_vE, columns=Sd.columns, index=[\"Flux set 1\", \"Flux set 2\", \"Flux set 3\"]).melt(ignore_index=False).reset_index(drop=False)\n",
    "df_recon[\"kind\"] = \"Reconstructed flux\"\n",
    "\n",
    "df_reconstr_comp = pd.concat([df_vE, df_recon]).reset_index(drop=True)\n",
    "df_reconstr_comp"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d228ba63b89758b7",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "source": [
    "sns.catplot(x=\"index\", y=\"value\", hue=\"kind\", col=\"variable\", kind=\"bar\", data=df_reconstr_comp, height=5, aspect=1, col_wrap=2)\n",
    "plt.savefig(\"flux_set_comparison.svg\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a647721354259573",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create class based method"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67ffa966bdf1c02e"
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "source": [
    "class ConvexKinetics:\n",
    "\n",
    "    def __init__(self, S_matrix):\n",
    "\n",
    "        self.regulation = False # TODO make this in a better way\n",
    "        self.loss = 0\n",
    "        self.constraints = []\n",
    "\n",
    "        self.n_met = len(S_matrix.index)\n",
    "        self.n_rxn = len(S_matrix.columns)\n",
    "\n",
    "        S_mol = np.array(S_matrix)   # has molecularity\n",
    "        self.S = np.sign(S_mol)      # has only +1 and -1 stoichiometries\n",
    "\n",
    "        self.S_s, self.S_p = -np.copy(self.S), np.copy(self.S) # reverse neg sign\n",
    "        self.S_s[self.S > 0] = 0 # zeros products\n",
    "        self.S_p[self.S < 0] = 0 # zeros substrates\n",
    "\n",
    "        self.S_s_nz = np.array(self.S_s.nonzero())    # substrate indices (metabolite, reaction)\n",
    "        self.S_p_nz = np.array(self.S_p.nonzero())    # product indices (metabolite, reaction)\n",
    "        self.S_s_mol = np.abs(S_mol)[self.S_s.nonzero()]  # substrate molecularity at indices\n",
    "        self.S_p_mol = np.abs(S_mol)[self.S_p.nonzero()]  # product molecularity at indices\n",
    "\n",
    "        # TODO Refactor all the below lines as one liners\n",
    "        # first coordinate, e.g. metabolites w nonzero substrate/product coeff across all reactions. also works as substrate indices.\n",
    "        self.met_s_nz, self.met_p_nz = self.S_s_nz[0, :], self.S_p_nz[0, :]     #\n",
    "\n",
    "        # second coordinate, e.g. reactions indices for those concentrations. works to index substrates as well.\n",
    "        self.rxn_s_nz, self.rxn_p_nz = self.S_s_nz[1, :], self.S_p_nz[1, :]\n",
    "\n",
    "        # one dim is always 2\n",
    "        n_Km_s, n_Km_p = len(self.met_s_nz), len(self.met_p_nz) # number of substrate and product Km\n",
    "\n",
    "        self.Km_s, self.Km_p = cp.Variable(n_Km_s), cp.Variable(n_Km_p) # substrate and product Km\n",
    "        self.cfwd, self.crev = cp.Variable(n_rxn), cp.Variable(n_rxn) # forward and reverse reaction rate constants\n",
    "\n",
    "    def add_regulation(self, regulation_matrix):\n",
    "\n",
    "        # TODO Assert that regulation matrix has same order of metabolites as S matrix\n",
    "\n",
    "        Sr = regulation_matrix\n",
    "\n",
    "        self.S_i = np.copy(np.array(Sr) == -1) # reaction direction does not matter\n",
    "        self.S_a = np.copy(np.array(Sr) == 1)\n",
    "\n",
    "        S_i_nz = np.array(self.S_i.nonzero())\n",
    "        S_a_nz = np.array(self.S_a.nonzero())\n",
    "\n",
    "        self.met_i_nz, self.met_a_nz = S_i_nz[0, :], S_a_nz[0, :]\n",
    "        self.rxn_i_nz, self.rxn_a_nz = S_i_nz[1, :], S_a_nz[1, :]\n",
    "\n",
    "        n_Km_i, n_Km_a = len(self.met_i_nz), len(self.met_a_nz)\n",
    "        self.Km_i = cp.Variable(n_Km_i) if n_Km_i else None\n",
    "        self.Km_a = cp.Variable(n_Km_a) if n_Km_a else None\n",
    "\n",
    "        self.regulation = True\n",
    "\n",
    "    def add_flow_data(self, flow_data):\n",
    "\n",
    "        # TODO assert flux columns are identical to S_matrix columns\n",
    "        self.n_flux_set = len(flow_data.index)\n",
    "        self.flow_data = np.array(flow_data)\n",
    "\n",
    "        self.c = cp.Variable([self.n_met, self.n_flux_set])    # concentrations\n",
    "\n",
    "        y_s_t, y_p_t, y_i_t, y_a_t = [], [], [], []\n",
    "\n",
    "        # define Km positions by nonzero S matrix concentrations. Activation is reverse val of inhibition.\n",
    "        for i in range(self.n_flux_set):\n",
    "            y_s_t.append(cp.multiply(self.S_s_mol, self.c[self.met_s_nz, i] - self.Km_s))\n",
    "            y_p_t.append(cp.multiply(self.S_p_mol, self.c[self.met_p_nz, i] - self.Km_p))\n",
    "            y_i_t.append(self.c[self.met_i_nz, i] - self.Km_i if self.Km_i else None)\n",
    "            y_a_t.append(-(self.c[self.met_a_nz, i] - self.Km_a) if self.Km_a else None)\n",
    "\n",
    "        self.y_s, self.y_p, self.y_i, self.y_a = cp.vstack(y_s_t), cp.vstack(y_p_t), cp.vstack(y_i_t), cp.vstack(y_a_t)\n",
    "\n",
    "        y_f_vec, y_r_vec = [self.y_s], [self.y_p]\n",
    "        if self.Km_i:\n",
    "            y_f_vec.append(self.y_i)\n",
    "            y_r_vec.append(self.y_i)\n",
    "        if self.Km_a:\n",
    "            y_f_vec.append(self.y_a)\n",
    "            y_r_vec.append(self.y_a)\n",
    "\n",
    "        self.y_f, self.y_r = cp.hstack(y_f_vec), cp.hstack(y_r_vec)\n",
    "\n",
    "    def construct_binding_matrix(self):\n",
    "\n",
    "        # number of saturation terms for sub, prod\n",
    "        # make the code below cleaner\n",
    "        S_s_comb = np.concatenate((self.S_s, self.S_i, self.S_a), axis=0)  if self.regulation else self.S_s\n",
    "        S_p_comb = np.concatenate((self.S_p, self.S_i, self.S_a), axis=0) if self.regulation else self.S_p\n",
    "        n_alpha = np.sum(np.power(2, np.sign(S_s_comb).sum(axis=0)) - 1)\n",
    "        n_beta = np.sum(np.power(2, np.sign(S_p_comb).sum(axis=0)) - 1)\n",
    "\n",
    "        # saturation matrix setup, first sub, then inhib, then act.\n",
    "        C_alpha = np.zeros([n_alpha, len(self.met_s_nz) + len(self.met_i_nz) + len(self.met_a_nz)])\n",
    "        C_beta = np.zeros([n_beta, len(self.met_p_nz) + len(self.met_i_nz) + len(self.met_a_nz)])\n",
    "\n",
    "        # to separate different reactions saturation terms to their individual reaction equations.\n",
    "        d_alpha, d_beta = np.zeros(n_alpha, dtype=np.int8), np.zeros(n_beta, dtype=np.int8)\n",
    "\n",
    "        s_idx, p_idx = 0, 0\n",
    "\n",
    "        for i in range(n_rxn):\n",
    "            # pick one reaction at a time (get substrate indicies)\n",
    "            idx_s_cur_rxn = np.concatenate((self.rxn_s_nz == i, self.rxn_i_nz == i, self.rxn_a_nz == i))\n",
    "            idx_p_cur_rxn = np.concatenate((self.rxn_p_nz == i, self.rxn_i_nz == i, self.rxn_a_nz == i))\n",
    "\n",
    "            # generates all binary permutations minus the first one since that would result in -1\n",
    "            s_sat_perm = np.array(list(itertools.product([0, 1], repeat=sum(idx_s_cur_rxn))))[1:, :]\n",
    "            p_sat_perm = np.array(list(itertools.product([0, 1], repeat=sum(idx_p_cur_rxn))))[1:, :]\n",
    "\n",
    "            r_s, _ = s_sat_perm.shape\n",
    "            r_p, _ = p_sat_perm.shape\n",
    "\n",
    "            # replace zeros with saturation matrix\n",
    "            C_alpha[s_idx:(s_idx+r_s), idx_s_cur_rxn] = s_sat_perm\n",
    "            d_alpha[s_idx:(s_idx+r_s)] = i\n",
    "\n",
    "            C_beta[p_idx:(p_idx+r_p), idx_p_cur_rxn] = p_sat_perm\n",
    "            d_beta[p_idx:(p_idx+r_p)] = i\n",
    "\n",
    "            s_idx += r_s # add number of rows added.\n",
    "            p_idx += r_p #\n",
    "\n",
    "        self.C_alpha, self.C_beta, self.d_alpha, self.d_beta = C_alpha, C_beta, d_alpha, d_beta\n",
    "\n",
    "    def construct_kinetic_objective(self):\n",
    "\n",
    "        # TODO\n",
    "        LSE_expr, denom_expr = [], []\n",
    "\n",
    "        sign = np.sign(self.flow_data)\n",
    "        lvE = np.log(sign * self.flow_data)\n",
    "\n",
    "        for j in range(self.n_flux_set):\n",
    "            for i in range(self.n_rxn):\n",
    "                # sum terms are separate in logsumexp. one per saturation term (row in C_alpha, C_beta)\n",
    "\n",
    "                Km_s_idx = np.nonzero(self.rxn_s_nz == i) # TODO have to set as attribute\n",
    "                S_s_idx = self.S_s_nz[0, self.rxn_s_nz == i] # negate -1 entries\n",
    "\n",
    "                Km_p_idx = np.nonzero(self.rxn_p_nz == i)\n",
    "                S_p_idx = self.S_p_nz[0, self.rxn_p_nz == i]\n",
    "\n",
    "                if sign[j, i] == 1:\n",
    "                    expr_num = [\n",
    "                                lvE[j, i] + (self.C_alpha @ cp.vec(self.y_f[j, :]))[self.d_alpha == i],\n",
    "                                lvE[j, i] + (self.C_beta @ cp.vec(self.y_r[j, :]))[self.d_beta == i],\n",
    "                                lvE[j, i] + 0,\n",
    "                                self.S.T[i, S_p_idx] @ cp.vec(self.y_p[j, Km_p_idx])  + self.crev[i] # TODO did removing multiply break this?\n",
    "                                ] # TODO first three terms are the same. can be combined outside if statement\n",
    "\n",
    "                    expr_denom = - (- self.S.T[i, S_s_idx] @ cp.vec(self.y_s[j, Km_s_idx])) - self.cfwd[i]\n",
    "                    expr = cp.hstack(expr_num) + expr_denom # TODO this might be wrong\n",
    "                    LSE_expr.append(expr) # TODO vectorize this\n",
    "\n",
    "                    denom_expr.append(-expr_denom) # TODO vectorize this\n",
    "\n",
    "\n",
    "                # keep saturation term the same, switch around fwd and rev terms. flip all signs with S matrix since it's signed.\n",
    "                if sign[j, i] == -1:\n",
    "                    expr_num = [\n",
    "                                lvE[j, i] + (self.C_alpha @ cp.vec(self.y_f[j, :]))[self.d_alpha == i],\n",
    "                                lvE[j, i] + (self.C_beta @ cp.vec(self.y_r[j, :]))[self.d_beta == i],\n",
    "                                lvE[j, i] + 0,\n",
    "                                - self.S.T[i, S_s_idx] @ cp.vec(self.y_s[j, Km_s_idx]) + self.cfwd[i]\n",
    "                                ]\n",
    "\n",
    "                    expr_denom = - (self.S.T[i, S_p_idx] @ cp.vec(self.y_p[j, Km_p_idx])) - self.crev[i]\n",
    "                    expr = cp.hstack(expr_num) + expr_denom # TODO this might be wrong\n",
    "\n",
    "                    LSE_expr.append(expr)\n",
    "\n",
    "                    denom_expr.append(cp.multiply(np.ones(1), S.T[i, S_p_idx] @ cp.vec(y_p[j, Km_p_idx])) + crev[i])\n",
    "\n",
    "            self.LSE_expr, self.denom_expr = LSE_expr, denom_expr\n",
    "\n",
    "    def create_objective_function(self, prior_weight = 0.0001, l1_weight = 0.0001, denom_weight = 0.01):\n",
    "\n",
    "        p = prior_weight\n",
    "        l1 = l1_weight\n",
    "        l1_term =  cp.sum(cp.hstack([self.cfwd, self.crev, cp.vec(self.c)])) + cp.sum(cp.hstack([-self.Km_s, -self.Km_p])) # regularization (l1 because geometric)\n",
    "        p_term = cp.norm1(cp.hstack([self.cfwd, self.crev, cp.vec(self.c)])) + cp.norm1(cp.hstack([-self.Km_s, -self.Km_p])) # regularization # TODO these are conflicting also prior\n",
    "\n",
    "        if self.Km_i is not None:\n",
    "            l1_term += cp.sum(cp.hstack([-self.Km_i]))\n",
    "        if self.Km_a is not None:\n",
    "            l1_term += cp.sum(cp.hstack([-self.Km_a])) # TODO this might break if no Km\n",
    "\n",
    "        for i in range(len(self.LSE_expr)):\n",
    "            self.loss += cp.norm1(cp.pos(cp.log_sum_exp(self.LSE_expr[i])))\n",
    "        for i in range(len(self.denom_expr)):\n",
    "            self.loss += denom_weight * self.denom_expr[i]\n",
    "\n",
    "        self.loss += l1 * l1_term + p * p_term\n",
    "\n",
    "    def set_parameter_bounds(self, lower_bound = -12, upper_bound = 12):\n",
    "\n",
    "        self.constraints.append(cp.hstack([self.cfwd, self.crev, cp.vec(self.c), self.Km_s, self.Km_p]) >= lower_bound)\n",
    "        self.constraints.append(cp.hstack([self.cfwd, self.crev, cp.vec(self.c), self.Km_s, self.Km_p]) <= upper_bound) # TODO might be append lol\n",
    "\n",
    "        if self.Km_i:\n",
    "            self.constraints.extend([self.Km_i >= -lower_bound, self.Km_i <= upper_bound])\n",
    "        if self.Km_a:\n",
    "            self.constraints.extend([self.Km_a >= -lower_bound, self.Km_a <= upper_bound])\n",
    "\n",
    "    def add_mechanistic_constraints(self, K_eq):\n",
    "\n",
    "        # TODO Assert that order of K_eq is the same as order of self.S (dict)\n",
    "        sign = np.sign(self.flow_data)\n",
    "        haldane = []\n",
    "        fwd_flux = []\n",
    "\n",
    "        for i, r in enumerate(self.S.T):    # TODO do this for kinetic objective creation\n",
    "            Km_s_idx = np.nonzero(self.rxn_s_nz == i) # TODO have to set as attribute\n",
    "            S_s_idx = self.S_s_nz[0, self.rxn_s_nz == i] # negate -1 entries\n",
    "\n",
    "            Km_p_idx = np.nonzero(self.rxn_p_nz == i)\n",
    "            S_p_idx = self.S_p_nz[0, self.rxn_p_nz == i]\n",
    "\n",
    "            haldane.append(K_eq[i] == self.cfwd[i] - self.crev[i] + r[S_p_idx] @ self.Km_p[Km_p_idx] - (-r[S_s_idx]) @ self.Km_s[Km_s_idx])\n",
    "\n",
    "        for j in range(self.n_flux_set):\n",
    "            for i, r in enumerate(self.S.T): # TODO use the above for loop\n",
    "                Km_s_idx = np.nonzero(self.rxn_s_nz == i) # TODO have to set as attribute\n",
    "                S_s_idx = self.S_s_nz[0, self.rxn_s_nz == i] # negate -1 entries\n",
    "\n",
    "                Km_p_idx = np.nonzero(self.rxn_p_nz == i)\n",
    "                S_p_idx = self.S_p_nz[0, self.rxn_p_nz == i]\n",
    "\n",
    "                if sign[j, i] == 1:\n",
    "                    fwd_flux.append(self.cfwd[i] + (-r[S_s_idx]) @ cp.vec(self.y_s[j, Km_s_idx])\n",
    "                                    - (self.crev[i] + r[S_p_idx] @ cp.vec(self.y_p[j, Km_p_idx]))  >= 0)  # add minus since s matrix has minus\n",
    "\n",
    "                if sign[j, i] == -1:\n",
    "                    fwd_flux.append(self.cfwd[i] + (-r[S_s_idx]) @ cp.vec(self.y_s[j, Km_s_idx])\n",
    "                                    - (self.crev[i] + r[S_p_idx] @ cp.vec(self.y_p[j, Km_p_idx]))  <= 0)  # add minus since s matrix has minus\n",
    "\n",
    "            self.constraints.extend([cp.multiply(self.S.T @ cp.vec(self.c[:, j]), sign[j, :])  <= cp.multiply(K_eq, sign[j, :])])\n",
    "\n",
    "        self.constraints.extend(haldane)\n",
    "        self.constraints.extend(fwd_flux)\n",
    "\n",
    "    def solve(self, solver = cp.ECOS, verbose = False, **kwargs):\n",
    "\n",
    "        self.problem = cp.Problem(cp.Minimize(self.loss), self.constraints)\n",
    "        self.problem.solve(solver = solver, verbose = verbose, **kwargs)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b69d5bfe607b028f",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "source": [
    "E = ConvexKinetics(Sd)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1e01e3dbaeec81",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "source": [
    "E.add_regulation(Sr)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b730e437a506b898",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "source": [
    "E.add_flow_data(pd.DataFrame(np.array([vE])))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "458abe9570dd0f81",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "source": [
    "E.construct_binding_matrix()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c5c548e7eea901a",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "source": [
    "E.construct_kinetic_objective()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8a44a6093c4f92a",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "source": [
    "E.create_objective_function()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "647df6879ee2c8d1",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "source": [
    "E.set_parameter_bounds()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd03d80326e5cfc4",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "source": [
    "E.add_mechanistic_constraints(K_eq)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a233767e22425119",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "source": [
    "E.solve(verbose=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "935ceb218de6f814",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "source": [
    "Sr\n",
    "\n",
    "# define y vecs\n",
    "# make the code below more efficient\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50ec95f768727030",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "haldane = []\n",
    "fwd_flux = []\n",
    "\n",
    "for i, r in enumerate(S.T):\n",
    "    Km_s_idx = np.nonzero(S_s_nz[1, :] == i)\n",
    "    S_s_idx = S_s_nz[0, S_s_nz[1, :] == i] # negate -1 entries\n",
    "\n",
    "    Km_p_idx = np.nonzero(S_p_nz[1, :] == i)\n",
    "    S_p_idx = S_p_nz[0, S_p_nz[1, :] == i]\n",
    "\n",
    "    haldane.append(K_eq[i] == cfwd[i] - crev[i] + r[S_p_idx] @ Km_p[Km_p_idx] - (-r[S_s_idx]) @ Km_s[Km_s_idx])\n",
    "\n",
    "for j in range(n_flux_set):\n",
    "    for i, r in enumerate(S.T):\n",
    "        Km_s_idx = np.nonzero(S_s_nz[1, :] == i)\n",
    "        S_s_idx = S_s_nz[0, S_s_nz[1, :] == i] # negate -1 entries\n",
    "\n",
    "        Km_p_idx = np.nonzero(S_p_nz[1, :] == i)\n",
    "        S_p_idx = S_p_nz[0, S_p_nz[1, :] == i]\n",
    "\n",
    "        if sign[j, i] == 1:\n",
    "            fwd_flux.append(cfwd[i] + (-r[S_s_idx]) @ cp.vec(y_s[j, Km_s_idx]) - (crev[i] + r[S_p_idx] @ cp.vec(y_p[j, Km_p_idx]))  >= 0)  # add minus since s matrix has minus\n",
    "\n",
    "        if sign[j, i] == -1:\n",
    "            fwd_flux.append(cfwd[i] + (-r[S_s_idx]) @ cp.vec(y_s[j, Km_s_idx]) - (crev[i] + r[S_p_idx] @ cp.vec(y_p[j, Km_p_idx]))  <= 0)  # add minus since s matrix has minus\n",
    "\n",
    "    constr.extend([cp.multiply(S.T @ cp.vec(c[:, j]), sign[j, :])  <= cp.multiply(K_eq, sign[j, :])])\n",
    "\n",
    "constr.extend(haldane)\n",
    "constr.extend(fwd_flux)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4dddda10a8b90ed7",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
