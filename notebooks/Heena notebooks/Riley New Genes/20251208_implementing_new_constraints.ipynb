{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Riley's new gene project has shown that when a GFP gene is induced in the e.coli, there is a consistent shift of proteome fraction of essential proteins. i.e. most essential proteins have like 10% smaller fraction compared to wild type e.coli. The purpose of this notebook is to identify any connection between the decrease in expression of these essential proteins and potential metabolic defect. For this purpose, we will 1). import the complex ids of essential proteins that have decreased proteome fraction, 2). identify the kinetic reactions catalyzed by some of these complexes, 3). perform FBA to see if there is any metabolic defect when these reactions are knocked downed (80% for instance).\n",
    "\n",
    "#### Since nothing was observed when knocking down by target, now we will try forcing the flux through these reactions to be at most 80% of WT fluxes via constraints."
   ],
   "id": "610390f0ccfdc3b9"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-09T01:02:07.354192Z",
     "start_time": "2025-12-09T01:02:05.304040Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import os, dill\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "from typing import Iterable, Optional, Mapping, cast\n",
    "from plotly.graph_objects import Scatter, Figure\n",
    "\n",
    "from ecoli.processes.metabolism_redux_classic import NetworkFlowModel, FlowResult\n",
    "os.chdir(os.path.expanduser('~/dev/vEcoli'))\n",
    "\n",
    "%load_ext autoreload"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T01:02:09.512484Z",
     "start_time": "2025-12-09T01:02:07.392522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import complex id of interest from txt\n",
    "complex_ids_txt = pd.read_csv('notebooks/Heena notebooks/Riley New Genes/proteome_fraction_scatterplot_below_line_essential_complex_ids_16.txt', header=None)\n",
    "complex_ids = np.unique(complex_ids_txt[0].tolist())\n",
    "\n",
    "# import kinetic reaction info from sim result\n",
    "time = '600'\n",
    "date = '2025-11-30'\n",
    "experiment = 'output_objective_weights'\n",
    "condition = 'basal'\n",
    "entry = f'{experiment}_{time}_{date}'\n",
    "folder = f'out/objective_weight/{condition}/{entry}/'\n",
    "\n",
    "output = np.load(folder + '0_output.npy',allow_pickle='TRUE').item()\n",
    "output = output['agents']['0']\n",
    "fba = output['listeners']['fba_results']\n",
    "bulk = pd.DataFrame(output['bulk'])\n",
    "f = open(folder + 'agent_steps.pkl', 'rb')\n",
    "agent = dill.load(f)\n",
    "f.close()"
   ],
   "id": "e88b2354c6ac5f20",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T01:02:09.681977Z",
     "start_time": "2025-12-09T01:02:09.627726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get commonly stored variables\n",
    "metabolism = agent['ecoli-metabolism-redux-classic']\n",
    "stoichiometry = metabolism.stoichiometry.copy()\n",
    "reaction_names = metabolism.reaction_names\n",
    "fba_new_reaction_ids = metabolism.parameters[\"fba_new_reaction_ids\"]\n",
    "fba_reaction_ids_to_base_reaction_ids = metabolism.parameters['fba_reaction_ids_to_base_reaction_ids']\n",
    "metabolites = metabolism.metabolite_names.copy()\n",
    "binary_kinetic_idx = metabolism.binary_kinetic_idx\n",
    "exchange_molecules = metabolism.exchange_molecules\n",
    "kinetic_enzymes = metabolism.parameters['kinetic_constraint_enzymes']\n",
    "\n",
    "S = stoichiometry .copy()\n",
    "S = pd.DataFrame(S, index=metabolites , columns=reaction_names )\n",
    "homeostatic_count = pd.DataFrame(fba[\"homeostatic_metabolite_counts\"], columns=metabolism.homeostatic_metabolites).mean(axis=0)\n",
    "homeostatic = pd.DataFrame(fba[\"target_homeostatic_dmdt\"], columns=metabolism.homeostatic_metabolites).mean(axis=0)\n",
    "maintenance = pd.DataFrame(fba[\"maintenance_target\"][1:], columns=['maintenance_reaction']).mean(axis=0)\n",
    "kinetic = pd.DataFrame(fba[\"target_kinetic_fluxes\"], columns=metabolism.kinetic_constraint_reactions).mean(axis=0).copy()\n",
    "\n",
    "kinetic_reaction_ids = metabolism.kinetic_constraint_reactions\n",
    "allowed_exchange_uptake = metabolism.allowed_exchange_uptake\n",
    "FREE_RXNS = [\"TRANS-RXN-145\", \"TRANS-RXN0-545\", \"TRANS-RXN0-474\"]"
   ],
   "id": "2841b06f91c2c7af",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T01:02:09.832250Z",
     "start_time": "2025-12-09T01:02:09.829636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get overlap between kinetic catalyst and complexes of interest\n",
    "kinetic_catalyst_overlapped = np.intersect1d(kinetic_enzymes, complex_ids)\n",
    "print(f'There are {len(kinetic_catalyst_overlapped)} complexes of interest that are also kinetic catalysts.')"
   ],
   "id": "2b95c31cbceea7e2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 54 complexes of interest that are also kinetic catalysts.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T01:02:10.091074Z",
     "start_time": "2025-12-09T01:02:10.078390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# link them to kinetic reactions\n",
    "kinetic_reaction_catalysts = {key:metabolism.parameters['reaction_catalysts'].get(key) for key in kinetic_reaction_ids}\n",
    "kinetic_reaction_catalysts_essential = {key:value for key, value in kinetic_reaction_catalysts.items() if np.any(np.isin(value, kinetic_catalyst_overlapped))}"
   ],
   "id": "2ffaf261996f858c",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Test FBA with decreased kinetic target for these reactions",
   "id": "f4b9105eabec0825"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T01:02:10.547091Z",
     "start_time": "2025-12-09T01:02:10.147237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "kinetic_reaction_id_essential = kinetic_reaction_catalysts_essential.keys()\n",
    "kinetic_target_essential = kinetic.loc[kinetic_reaction_id_essential]\n",
    "\n",
    "\n",
    "# all reactions\n",
    "sim = pd.DataFrame(fba[\"estimated_fluxes\"], columns= reaction_names).mean(axis=0).copy()\n",
    "\n",
    "# kinetic reactions\n",
    "kc_target = pd.DataFrame(fba[\"target_kinetic_fluxes\"], columns= kinetic_reaction_ids).mean(axis=0).copy()\n",
    "\n",
    "# get kinetic_reaction_idx\n",
    "kinetic_reaction_idx = np.array([reaction_names.index(id) for id in kinetic_reaction_ids])\n",
    "\n",
    "# form idx, flux dict\n",
    "WT_fluxes = sim.iloc[kinetic_reaction_idx]\n",
    "\n",
    "kinetic_constraint_dict = dict(zip(kinetic_reaction_idx,WT_fluxes))"
   ],
   "id": "47f575a79a467956",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T01:02:10.666871Z",
     "start_time": "2025-12-09T01:02:10.660364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_subset_S(S, met_of_interest):\n",
    "    S_met = S.loc[met_of_interest, :]\n",
    "    S_met = S_met.loc[:,~np.all(S_met == 0, axis=0)]\n",
    "    return S_met, S_met.columns\n",
    "\n",
    "def get_keys(dict, value):\n",
    "    return [key for key in dict if np.any(np.isin(value, dict[key]))]\n",
    "\n",
    "def test_NetworkFlowModel(objective_weights,\n",
    "                          uptake_addition = set([]), uptake_removal = set([]), new_exchange_molecules = set([]),\n",
    "                          add_metabolite = None, add_reaction = None, add_kinetic = None, remove_reaction = None, force_reaction = None,\n",
    "                          add_homeostatic_demand = None, solver_choice=cp.GLOP):\n",
    "    # update exchanges\n",
    "    uptake = metabolism.allowed_exchange_uptake.copy()\n",
    "    uptake = set(uptake)\n",
    "    uptake = uptake | uptake_addition\n",
    "    uptake = uptake - uptake_removal\n",
    "\n",
    "    exchange_molecules = metabolism.exchange_molecules.copy()\n",
    "    exchange_molecules = exchange_molecules | new_exchange_molecules\n",
    "\n",
    "    # update stoichiometry\n",
    "    reaction_names = metabolism.reaction_names.copy()\n",
    "    kinetic_reaction_ids = metabolism.kinetic_constraint_reactions.copy()\n",
    "    kinetic = pd.DataFrame(fba[\"target_kinetic_fluxes\"], columns=metabolism.kinetic_constraint_reactions).loc[24, :].copy()\n",
    "    metabolites = metabolism.metabolite_names.copy()\n",
    "    homeostatic_counts = homeostatic_count.copy() * metabolism.counts_to_molar.asNumber()\n",
    "\n",
    "    S_new = stoichiometry.copy()\n",
    "\n",
    "    if add_metabolite is not None: # add to metabolites list because they are currently not included in the model\n",
    "        for m in add_metabolite:\n",
    "            if m not in metabolites:\n",
    "                metabolites.append(m)\n",
    "        # append rows of zeros to S_new of length add_metabolite\n",
    "        S_new = np.concatenate((S_new, np.zeros((len(add_metabolite), S_new.shape[1]))), axis=0)\n",
    "\n",
    "    if add_reaction is not None:\n",
    "        # assert add_reaction is a dictionary\n",
    "        assert isinstance(add_reaction, dict)\n",
    "\n",
    "        for r,s in add_reaction.items():\n",
    "            if r not in reaction_names:\n",
    "                reaction_names.append(r)\n",
    "            # append columns of reaction stoich to S_new of length add_reaction\n",
    "            new_reaction = np.zeros((S_new.shape[0], 1))\n",
    "            for m, v in s.items():\n",
    "                new_reaction[metabolites.index(m), 0] = v\n",
    "            S_new = np.concatenate((S_new, new_reaction), axis=1)\n",
    "\n",
    "    if add_kinetic is not None:\n",
    "        # assert add_kinetic is a dictionary\n",
    "        assert isinstance(add_kinetic, dict)\n",
    "\n",
    "        for r, v in add_kinetic.items():\n",
    "            if r not in kinetic_reaction_ids:\n",
    "                kinetic_reaction_ids.append(r)\n",
    "                kinetic[r] = v\n",
    "            if r in kinetic_reaction_ids:\n",
    "                kinetic[r] = v\n",
    "\n",
    "    if remove_reaction is not None:\n",
    "        for r in remove_reaction:\n",
    "            r_idx = reaction_names.index(r)\n",
    "            S_new = np.delete(S_new, r_idx, axis=1)\n",
    "            reaction_names.remove(r)\n",
    "            if r in kinetic_reaction_ids:\n",
    "                kinetic_reaction_ids.remove(r)\n",
    "                del kinetic[r]\n",
    "\n",
    "    if force_reaction is not None:\n",
    "        force_reaction_idx = np.array([reaction_names.index(r) for r in force_reaction])\n",
    "    else:\n",
    "        force_reaction_idx = force_reaction\n",
    "\n",
    "    if add_homeostatic_demand is not None:\n",
    "        # assert add_homeostatic_demand is a set\n",
    "        assert isinstance(add_homeostatic_demand, list)\n",
    "\n",
    "        for met in add_homeostatic_demand:\n",
    "            homeostatic[met] = 100\n",
    "            homeostatic_counts[met] = 1\n",
    "\n",
    "    # Solve NetworkFlowModel\n",
    "    model = NetworkFlowModel(\n",
    "            stoich_arr=S_new,\n",
    "            metabolites=metabolites,\n",
    "            reactions=reaction_names,\n",
    "            homeostatic_metabolites=metabolism.homeostatic_metabolites,\n",
    "            kinetic_reactions=kinetic_reaction_ids,\n",
    "            free_reactions=FREE_RXNS)\n",
    "    model.set_up_exchanges(exchanges=exchange_molecules, uptakes=uptake)\n",
    "    solution: FlowResult = model.solve(\n",
    "            homeostatic_concs=homeostatic_counts, # in conc\n",
    "            homeostatic_dm_targets=np.array(list(dict(homeostatic).values())), # *10^7\n",
    "            maintenance_target=maintenance, # *10^6 ish\n",
    "            kinetic_targets=np.array(list(dict(kinetic).values())), # *10^6 ish\n",
    "            # binary_kinetic_idx=binary_kinetic_idx, #7646\n",
    "            binary_kinetic_idx=None,\n",
    "            force_flow_idx=force_reaction_idx,\n",
    "            objective_weights=objective_weights, #same\n",
    "            upper_flux_bound= 1000000000, # increase to 10^9 because notebook runs FlowResult using Counts, WC runs using conc.,\n",
    "            kinetic_constraint=kinetic_constraint_dict,\n",
    "            kinetic_adjustment=0.8,\n",
    "            solver=solver_choice) #SCS. ECOS, MOSEK\n",
    "    return solution.objective, solution.velocities, reaction_names, S_new, solution.kinetic_term, solution.homeostatic_term, solution.secretion_term, solution.efficiency_term"
   ],
   "id": "47ffb6fc2f60230d",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T01:03:38.577038Z",
     "start_time": "2025-12-09T01:03:38.210226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "objective_weights = {'secretion': 0.0000001, 'efficiency': 0.000001, 'kinetics': 0.00001, 'homeostatic': 1}\n",
    "(oofv, solution_flux, rxn_names, S_new, kinetic_soln, homeostatic_soln, secretion_soln, efficiency_soln) = (\n",
    "    test_NetworkFlowModel(objective_weights))\n",
    "oofv"
   ],
   "id": "ca8c04f1b87756bd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(228743.41579527492)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
